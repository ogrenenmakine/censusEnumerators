{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "import mxnet as mx\n",
    "global pi\n",
    "pi = 3.14\n",
    "from source.NACDDetection import NACDDetection\n",
    "from source import NACDTransform\n",
    "from gluoncv.data.transforms.bbox import crop as bbox_crop\n",
    "from gluoncv.utils import bbox_iou\n",
    "from gluoncv.data.transforms import bbox as tbbox\n",
    "from gluoncv.data.transforms import image as timage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NACDDetection(splits=[('NACDwNegswAug', 'train')])\n",
    "test_dataset = NACDDetection(splits=[('NACDwNegswAug', 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop_with_constraints(bbox, size, height, width, min_scale=0.9, max_scale=1.1,\n",
    "                                 max_aspect_ratio=2, constraints=None,\n",
    "                                 max_trial=1000):\n",
    "    # default params in paper\n",
    "    if constraints is None:\n",
    "        constraints = (\n",
    "            (0.1, None),\n",
    "            (0.3, None),\n",
    "            (0.5, None),\n",
    "            (0.7, None),\n",
    "            (0.9, None),\n",
    "            (None, 1),\n",
    "        )\n",
    "    if len(bbox) == 0:\n",
    "        constraints = []\n",
    "    w, h = size\n",
    "    candidates = []\n",
    "    for min_iou, max_iou in constraints:\n",
    "        min_iou = -np.inf if min_iou is None else min_iou\n",
    "        max_iou = np.inf if max_iou is None else max_iou\n",
    "\n",
    "        for _ in range(max_trial):\n",
    "            scale = random.uniform(min_scale, max_scale)\n",
    "            aspect_ratio = random.uniform(\n",
    "                max(1 / max_aspect_ratio, scale * scale),\n",
    "                min(max_aspect_ratio, 1 / (scale * scale)))\n",
    "            crop_h = int(height * scale / np.sqrt(aspect_ratio))\n",
    "            crop_w = int(width * scale * np.sqrt(aspect_ratio))\n",
    "\n",
    "            crop_t = random.randrange(h - crop_h)\n",
    "            crop_l = random.randrange(w - crop_w)\n",
    "            crop_bb = np.array((crop_l, crop_t, crop_l + crop_w, crop_t + crop_h))\n",
    "\n",
    "            iou = bbox_iou(bbox, crop_bb[np.newaxis])\n",
    "            if min_iou <= iou.min() and iou.max() <= max_iou:\n",
    "                top, bottom = crop_t, crop_t + crop_h\n",
    "                left, right = crop_l, crop_l + crop_w\n",
    "                candidates.append((left, top, right-left, bottom-top))\n",
    "                break\n",
    "\n",
    "    # random select one\n",
    "    while candidates:\n",
    "        crop = candidates.pop(np.random.randint(0, len(candidates)))\n",
    "        new_bbox = bbox_crop(bbox, crop, allow_outside_center=False)\n",
    "        if new_bbox.size < 1:\n",
    "            continue\n",
    "        new_crop = (crop[0], crop[1], crop[2], crop[3])\n",
    "        return new_bbox, new_crop\n",
    "    return random_crop_with_constraints(bbox, (w, h), height, width,min_scale=0.9,max_scale=1.1,max_trial=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from pascal_voc_writer import Writer\n",
    "for j in range(4):\n",
    "    for (i,batch) in enumerate(train_dataset):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        c = random.uniform(0.75, 1.2)\n",
    "        height = int(round(1150*c))\n",
    "        width = int(round(1150*c))\n",
    "        h, w, d = x.shape\n",
    "        new_bbox, new_crop = random_crop_with_constraints(y[:,:4],(w,h),width, height)\n",
    "        x0, y0, w, h = new_crop\n",
    "        img = mx.image.fixed_crop(x, x0, y0, w, h)\n",
    "        h, w, _ = img.shape\n",
    "        img = timage.imresize(img, 750, 750)\n",
    "        bbox = tbbox.resize(new_bbox, (w, h), (750, 750))\n",
    "        _str = '/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/JPEGImages/train_'+str(i)+'_'+str(j)+'.jpg'\n",
    "        image.imsave(_str, img.asnumpy())\n",
    "        writer = Writer(_str, 750, 750)\n",
    "        for t in range(len(bbox)):\n",
    "            if y[:,4].any() == 0:\n",
    "                writer.addObject('negative', int(bbox[t][0]), int(bbox[t][1]), int(bbox[t][2]), int(bbox[t][3]))\n",
    "            if y[:,4].any() == 1:\n",
    "                writer.addObject('cluster', int(bbox[t][0]), int(bbox[t][1]), int(bbox[t][2]), int(bbox[t][3]))\n",
    "        _str = '/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/Annotations/train_'+str(i)+'_'+str(j)+'.xml'\n",
    "        writer.save(_str)\n",
    "        _str = 'train_'+str(i)+'_'+str(j)\n",
    "        with open('/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/ImageSets/Main/train.txt', 'a') as the_file:\n",
    "            the_file.write(_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from pascal_voc_writer import Writer\n",
    "for j in range(8):\n",
    "    for (i,batch) in enumerate(test_dataset):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        height = int(round(1000))\n",
    "        width = int(round(1000))\n",
    "        h, w, d = x.shape\n",
    "        new_bbox, new_crop = random_crop_with_constraints(y[:,:4],(w,h),width, height)\n",
    "        x0, y0, w, h = new_crop\n",
    "        img = mx.image.fixed_crop(x, x0, y0, w, h)\n",
    "        h, w, _ = img.shape\n",
    "        img = timage.imresize(img, 640, 640)\n",
    "        bbox = tbbox.resize(new_bbox, (w, h), (640, 640))\n",
    "        _str = '/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/JPEGImages/test_'+str(i)+'_'+str(j)+'.jpg'\n",
    "        image.imsave(_str, img.asnumpy())\n",
    "        writer = Writer(_str, 640, 640)\n",
    "        for t in range(len(bbox)):\n",
    "            if y[:,4].any() == 0:\n",
    "                writer.addObject('negative', int(bbox[t][0]), int(bbox[t][1]), int(bbox[t][2]), int(bbox[t][3]))\n",
    "            if y[:,4].any() == 1:\n",
    "                writer.addObject('cluster', int(bbox[t][0]), int(bbox[t][1]), int(bbox[t][2]), int(bbox[t][3]))\n",
    "        _str = '/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/Annotations/test_'+str(i)+'_'+str(j)+'.xml'\n",
    "        writer.save(_str)\n",
    "        _str = 'test_'+str(i)+'_'+str(j)\n",
    "        with open('/home/mcy/.mxnet/datasets/voc/VOCNACDwNegswAugCropped/ImageSets/Main/test.txt', 'a') as the_file:\n",
    "            the_file.write(_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz\n",
    "ax = viz.plot_bbox(img.asnumpy(), bbox)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
