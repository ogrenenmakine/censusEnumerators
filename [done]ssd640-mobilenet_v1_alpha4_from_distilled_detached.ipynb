{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.contrib.ndarray import MultiBoxPrior\n",
    "from mxnet.gluon.contrib import nn as nn_contrib\n",
    "from mxnet.gluon import nn\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict classes\n",
    "- channel `i*(num_class+1)` store the scores for this box contains only background\n",
    "- channel `i*(num_class+1)+1+j` store the scores for this box contains an object from the *j*-th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_predictor(num_anchors, num_classes):\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict anchor boxes\n",
    "- $t_x = (Y_x - b_x) / b_{width}$\n",
    "- $t_y = (Y_y - b_y) / b_{height}$\n",
    "- $t_{width} = (Y_{width} - b_{width}) / b_{width}$\n",
    "- $t_{height} = (Y_{height} - b_{height}) / b_{height}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_predictor(num_anchors):\n",
    "    return nn.Conv2D(num_anchors * 4, 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage preditions from multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_prediction(pred):\n",
    "    return nd.flatten(nd.transpose(pred, axes=(0, 2, 3, 1)))\n",
    "\n",
    "def concat_predictions(preds):\n",
    "    return nd.concat(*preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_layer(nfilters, stride, expension_constant):\n",
    "    out = nn.HybridSequential()\n",
    "    out.add(nn.Conv2D(nfilters, 3, strides=stride, padding=1, groups=nfilters, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(nfilters*expension_constant, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 0.25\n",
    "num_filters = int(32*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "def s16():\n",
    "    out = nn.HybridSequential()\n",
    "    # conv_0 layer\n",
    "    out.add(nn.Conv2D(num_filters, 3, strides=2, padding=1, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_1 layer\n",
    "    out.add(dp_layer(num_filters, 1, 2))\n",
    "    # conv_2 layer\n",
    "    out.add(dp_layer(num_filters*2, 2, 2))\n",
    "    # conv_3 layer\n",
    "    out.add(dp_layer(num_filters*4, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*4, 3, strides=2, padding=1, groups=num_filters*4, use_bias=False))\n",
    "    #out.load_parameters(\"weights/mobilenet_0_25_s16_dist.params\", ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out\n",
    "\n",
    "def s32():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*8, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_4_layer\n",
    "    out.add(dp_layer(num_filters*8, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*8, 3, strides=2, padding=1, groups=num_filters*8, use_bias=False))\n",
    "    #out.load_parameters(\"weights/mobilenet_0_25_s32_dist.params\", ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b1():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_6_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16, use_bias=False))\n",
    "    #out.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b2():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16, use_bias=False))\n",
    "    #out.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b3():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16, use_bias=False))\n",
    "    #out.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b4():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16, use_bias=False))\n",
    "    #out.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    #out.hybridize()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_model(num_anchors, num_classes):\n",
    "    class_preds = nn.Sequential()\n",
    "    box_preds = nn.Sequential()\n",
    "    \n",
    "    class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors))\n",
    "    \n",
    "    class_preds.add(class_predictor(num_anchors*3/2, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors*3/2))\n",
    "    \n",
    "    class_preds.add(class_predictor(num_anchors*3/2, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors*3/2))\n",
    "    \n",
    "    class_preds.add(class_predictor(num_anchors*3/2, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors*3/2))\n",
    "\n",
    "    class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors))\n",
    "    \n",
    "    class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "    box_preds.add(box_predictor(num_anchors))\n",
    "    \n",
    "    #class_preds.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    #box_preds.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "    return s16(), s32(), b1(), b2(), b3(), b4(), class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_forward(x, s16, s32, b1, b2, b3, b4, class_preds, box_preds, sizes, ratios):\n",
    "    default_anchors = []\n",
    "    predicted_boxes = []  \n",
    "    predicted_classes = []\n",
    "\n",
    "    x = s16(x).detach()\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[0], ratios=ratios[0]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[0](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[0](x)))\n",
    "    \n",
    "    x = s32(x).detach()\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[1], ratios=ratios[1]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[1](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[1](x)))\n",
    "    \n",
    "    x = b1(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[2], ratios=ratios[2]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[2](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[2](x)))\n",
    "    \n",
    "    x = b2(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[3], ratios=ratios[3]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[3](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[3](x)))\n",
    "    \n",
    "    x = b3(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[4], ratios=ratios[4]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[4](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[4](x)))\n",
    "\n",
    "    x = b4(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[5], ratios=ratios[5]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[5](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[5](x)))\n",
    "    \n",
    "    return default_anchors, predicted_classes, predicted_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class SSD(gluon.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(SSD, self).__init__(**kwargs)\n",
    "        self.anchor_sizes = [[0.1,0.24],[0.24,0.38],[0.38,0.52],[0.52,0.66],[0.66,0.8],[0.8,0.94],[0.94,1.08]]\n",
    "        self.anchor_ratios = [[1, 2, .5],[1, 2, .5, 3, 0.3],[1, 2, .5, 3, 0.3],[1, 2, .5, 3, 0.3],[1, 2, .5],[1, 2, .5]]\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.s16, self.s32, self.b1, self.b2, self.b3, self.b4, self.class_preds, self.box_preds = ssd_model(4, num_classes)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        default_anchors, predicted_classes, predicted_boxes = ssd_forward(x, self.s16, self.s32, self.b1, self.b2, self.b3, self.b4,\n",
    "            self.class_preds, self.box_preds, self.anchor_sizes, self.anchor_ratios)\n",
    "        anchors = concat_predictions(default_anchors)\n",
    "        box_preds = concat_predictions(predicted_boxes)\n",
    "        class_preds = concat_predictions(predicted_classes)\n",
    "        class_preds = nd.reshape(class_preds, shape=(0, -1, self.num_classes + 1))\n",
    "        \n",
    "        return anchors, class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs of SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SSD(2)\n",
    "#net.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "net.load_parameters(\"process/ssd_v1_alpha2_dist_136.params\",ctx=ctx)\n",
    "x = nd.zeros((1, 3, 640, 640),ctx=ctx)\n",
    "default_anchors, class_predictions, box_predictions = net(x)\n",
    "print('Outputs:', 'anchors', default_anchors.shape, 'class prediction', class_predictions.shape, 'box prediction', box_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.NACDDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train')])\n",
    "val_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'val')])\n",
    "test_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Val images:', len(val_dataset))\n",
    "print('Test images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd\n",
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import NACDTransform\n",
    "width, height = 640, 640\n",
    "train_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\n",
    "test_transform = presets.ssd.SSDDefaultValTransform(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label = test_dataset[0]\n",
    "bboxes = train_label[:, :4]\n",
    "cids = train_label[:, 4:5]\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2, train_label2 = train_transform(train_image, train_label)\n",
    "print('tensor shape:', train_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(test_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset.transform(test_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "for ib, batch in enumerate(test_loader):\n",
    "    if ib > 3:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "train_image2 = (train_image2 * 255).clip(0, 255)\n",
    "ax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxTarget\n",
    "def training_targets(default_anchors, class_predicts, labels):\n",
    "    class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))\n",
    "    z = MultiBoxTarget(anchor=default_anchors, label=labels, cls_pred=class_predicts)\n",
    "    box_target = z[0] # box offset target for (x, y, width, height)\n",
    "    box_mask = z[1]  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples\n",
    "    cls_target = z[2]  # cls_target is an array of labels for all anchors boxes\n",
    "    return box_target, box_mask, cls_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertlbl(y):\n",
    "    mtrx = y[:,:,0:4]\n",
    "    mtrx = mtrx.asnumpy()\n",
    "    mtrx[mtrx == -1] = -width\n",
    "    mtrx = mtrx/width\n",
    "    return mx.nd.concat(nd.expand_dims(y[:,:,4],2),mx.nd.array(mtrx),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(gluon.loss.Loss):\n",
    "    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n",
    "        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label):\n",
    "        output = F.softmax(output)\n",
    "        pt = F.pick(output, label, axis=self._axis, keepdims=True)\n",
    "        loss = -self._alpha * ((1 - pt) ** self._gamma) * F.log(pt)\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)\n",
    "\n",
    "# cls_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "cls_loss = FocalLoss()\n",
    "print(cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothL1Loss(gluon.loss.Loss):\n",
    "    def __init__(self, batch_axis=0, **kwargs):\n",
    "        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label, mask):\n",
    "        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n",
    "        return F.mean(loss, self._batch_axis, exclude=True)\n",
    "\n",
    "box_loss = SmoothL1Loss()\n",
    "print(box_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mxnet import autograd as ag\n",
    "from gluoncv.loss import SSDMultiBoxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop params\n",
    "epochs = 350\n",
    "start_epoch = 137\n",
    "\n",
    "# initialize trainer\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 1e-1, 'wd': 4e-5})\n",
    "\n",
    "# evaluation metrics\n",
    "cls_metric = mx.metric.Accuracy()\n",
    "box_metric = mx.metric.MAE()\n",
    "cls_metric_val = mx.metric.Accuracy()\n",
    "box_metric_val = mx.metric.MAE()\n",
    "cls_metric_test = mx.metric.Accuracy()\n",
    "box_metric_test = mx.metric.MAE()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    #train_data.reset()\n",
    "    cls_metric.reset()\n",
    "    box_metric.reset()\n",
    "    train_loss = 0\n",
    "    tic = time.time()\n",
    "    # iterate through all batch\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            x = batch[0].as_in_context(ctx)\n",
    "            lbl = convertlbl(batch[1]).as_in_context(ctx)\n",
    "            default_anchors, class_predictions, box_predictions = net(x)\n",
    "            box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "            # losses\n",
    "            loss1 = cls_loss(class_predictions, cls_target)\n",
    "            loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "            # sum all losses\n",
    "            loss = loss1 + loss2\n",
    "            train_loss += nd.sum(loss).asscalar()\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size, ignore_stale_grad=True)\n",
    "        # update metrics\n",
    "        cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "    name1_train, val1_train = cls_metric.get()\n",
    "    name2_train, val2_train = box_metric.get()\n",
    "    # Validation\n",
    "    cls_metric_val.reset()\n",
    "    box_metric_val.reset()\n",
    "    val_loss = 0\n",
    "    toc = time.time()\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        #tic = time.time()\n",
    "        # record gradients\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        lbl = convertlbl(batch[1]).as_in_context(ctx)\n",
    "        default_anchors, class_predictions, box_predictions = net(x)\n",
    "        box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "        # losses\n",
    "        loss1 = cls_loss(class_predictions, cls_target)\n",
    "        loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "        # sum all losses\n",
    "        loss = loss1 + loss2\n",
    "        val_loss += nd.sum(loss).asscalar()\n",
    "        # update metrics\n",
    "        cls_metric_val.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric_val.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "        #print(time.time()-tic)\n",
    "    name1_val, val1_val = cls_metric_val.get()\n",
    "    name2_val, val2_val = box_metric_val.get()\n",
    "    # Test\n",
    "    cls_metric_test.reset()\n",
    "    box_metric_test.reset()\n",
    "    test_loss = 0\n",
    "    toc = time.time()\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        #tic = time.time()\n",
    "        # record gradients\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        lbl = convertlbl(batch[1]).as_in_context(ctx)\n",
    "        default_anchors, class_predictions, box_predictions = net(x)\n",
    "        box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "        # losses\n",
    "        loss1 = cls_loss(class_predictions, cls_target)\n",
    "        loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "        # sum all losses\n",
    "        loss = loss1 + loss2\n",
    "        test_loss += nd.sum(loss).asscalar()\n",
    "        # update metrics\n",
    "        cls_metric_test.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric_test.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "        #print(time.time()-tic)\n",
    "    name1_test, val1_test = cls_metric_test.get()\n",
    "    name2_test, val2_test = box_metric_test.get()\n",
    "    print('epoch:%3d;\\t train:%.6e;%f;%.6e;\\t val:%.6e;%f;%.6e; test:%.6e;%f;%.6e;Speed:%d'\n",
    "          %(epoch, train_loss/len(train_dataset), val1_train, val2_train, val_loss/len(val_dataset), val1_val, val2_val, test_loss/len(test_dataset), val1_test, val2_test, len(train_dataset)/(toc-tic)))\n",
    "\n",
    "    net.save_parameters('process/ssd_v1_alpha2_dist_%d.params' % epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# epoch:  0;\t train:4.167190e-02;0.935392;6.647986e-03;\t val:2.300319e-02;0.981036;7.235131e-03; test:2.300319e-02;0.981036;7.235131e-03;Speed:39\n",
    "epoch:  1;\t train:2.031471e-02;0.986130;6.514192e-03;\t val:1.808342e-02;0.987232;7.096153e-03; test:1.808342e-02;0.987232;7.096153e-03;Speed:39\n",
    "epoch:  2;\t train:1.668469e-02;0.989224;6.530442e-03;\t val:1.556702e-02;0.989837;6.963002e-03; test:1.556702e-02;0.989837;6.963002e-03;Speed:40\n",
    "epoch:  3;\t train:1.450942e-02;0.991007;6.455402e-03;\t val:1.388871e-02;0.991200;6.855079e-03; test:1.388871e-02;0.991200;6.855079e-03;Speed:40\n",
    "epoch:  4;\t train:1.311114e-02;0.991920;6.455123e-03;\t val:1.267844e-02;0.991859;6.760619e-03; test:1.267844e-02;0.991859;6.760619e-03;Speed:40\n",
    "epoch:  5;\t train:1.208797e-02;0.992420;6.380906e-03;\t val:1.178613e-02;0.992168;6.682359e-03; test:1.178613e-02;0.992168;6.682359e-03;Speed:41\n",
    "epoch:  6;\t train:1.143013e-02;0.992637;6.380701e-03;\t val:1.114140e-02;0.992360;6.613681e-03; test:1.114140e-02;0.992360;6.613681e-03;Speed:40\n",
    "epoch:  7;\t train:1.097530e-02;0.992794;6.383945e-03;\t val:1.060334e-02;0.992512;6.561082e-03; test:1.060334e-02;0.992512;6.561082e-03;Speed:39\n",
    "epoch:  8;\t train:1.054956e-02;0.992908;6.382380e-03;\t val:1.016598e-02;0.992650;6.513307e-03; test:1.016598e-02;0.992650;6.513307e-03;Speed:40\n",
    "epoch:  9;\t train:1.017160e-02;0.993090;6.321450e-03;\t val:9.813876e-03;0.992771;6.470464e-03; test:9.813876e-03;0.992771;6.470464e-03;Speed:40\n",
    "epoch: 10;\t train:9.902778e-03;0.993189;6.316958e-03;\t val:9.507479e-03;0.992879;6.432817e-03; test:9.507479e-03;0.992879;6.432817e-03;Speed:40\n",
    "epoch: 11;\t train:9.582029e-03;0.993366;6.226440e-03;\t val:9.227253e-03;0.992964;6.402764e-03; test:9.227253e-03;0.992964;6.402764e-03;Speed:40\n",
    "epoch: 12;\t train:9.400935e-03;0.993424;6.245168e-03;\t val:8.994666e-03;0.993048;6.375841e-03; test:8.994666e-03;0.993048;6.375841e-03;Speed:41\n",
    "epoch: 13;\t train:9.374916e-03;0.993386;6.374133e-03;\t val:8.786303e-03;0.993105;6.352530e-03; test:8.786303e-03;0.993105;6.352530e-03;Speed:40\n",
    "epoch: 14;\t train:9.104543e-03;0.993530;6.267589e-03;\t val:8.610940e-03;0.993158;6.330067e-03; test:8.610940e-03;0.993158;6.330067e-03;Speed:40\n",
    "epoch: 15;\t train:8.894605e-03;0.993669;6.166813e-03;\t val:8.440615e-03;0.993134;6.303016e-03; test:8.440615e-03;0.993134;6.303016e-03;Speed:40\n",
    "epoch: 16;\t train:8.734698e-03;0.993722;6.167577e-03;\t val:8.299531e-03;0.993137;6.284265e-03; test:8.299531e-03;0.993137;6.284265e-03;Speed:40\n",
    "epoch: 17;\t train:8.620603e-03;0.993761;6.154092e-03;\t val:8.190837e-03;0.993194;6.272280e-03; test:8.190837e-03;0.993194;6.272280e-03;Speed:40\n",
    "epoch: 18;\t train:8.587990e-03;0.993737;6.214312e-03;\t val:8.070981e-03;0.993225;6.261127e-03; test:8.070981e-03;0.993225;6.261127e-03;Speed:40\n",
    "epoch: 19;\t train:8.421191e-03;0.993814;6.148413e-03;\t val:7.973918e-03;0.993176;6.242844e-03; test:7.973918e-03;0.993176;6.242844e-03;Speed:40\n",
    "epoch: 20;\t train:8.411414e-03;0.993775;6.202694e-03;\t val:7.881936e-03;0.993170;6.230558e-03; test:7.881936e-03;0.993170;6.230558e-03;Speed:40\n",
    "epoch: 21;\t train:8.283218e-03;0.993842;6.145213e-03;\t val:7.809516e-03;0.993239;6.224932e-03; test:7.809516e-03;0.993239;6.224932e-03;Speed:40\n",
    "epoch: 22;\t train:8.356334e-03;0.993738;6.270688e-03;\t val:7.748302e-03;0.993244;6.215939e-03; test:7.748302e-03;0.993244;6.215939e-03;Speed:41\n",
    "epoch: 23;\t train:8.217398e-03;0.993838;6.174972e-03;\t val:7.688279e-03;0.993124;6.198584e-03; test:7.688279e-03;0.993124;6.198584e-03;Speed:40\n",
    "epoch: 24;\t train:8.120149e-03;0.993848;6.161103e-03;\t val:7.625203e-03;0.993197;6.193418e-03; test:7.625203e-03;0.993197;6.193418e-03;Speed:40\n",
    "epoch: 25;\t train:8.076871e-03;0.993865;6.158381e-03;\t val:7.574236e-03;0.993181;6.185016e-03; test:7.574236e-03;0.993181;6.185016e-03;Speed:40\n",
    "epoch: 26;\t train:8.075350e-03;0.993820;6.199583e-03;\t val:7.520060e-03;0.993116;6.175354e-03; test:7.520060e-03;0.993116;6.175354e-03;Speed:40\n",
    "epoch: 27;\t train:8.041719e-03;0.993813;6.206773e-03;\t val:7.483901e-03;0.993064;6.166101e-03; test:7.483901e-03;0.993064;6.166101e-03;Speed:41\n",
    "epoch: 28;\t train:7.985802e-03;0.993844;6.185437e-03;\t val:7.447250e-03;0.993165;6.162141e-03; test:7.447250e-03;0.993165;6.162141e-03;Speed:40\n",
    "epoch: 29;\t train:7.927934e-03;0.993855;6.162970e-03;\t val:7.409087e-03;0.993128;6.152664e-03; test:7.409087e-03;0.993128;6.152664e-03;Speed:40\n",
    "epoch: 30;\t train:7.918333e-03;0.993829;6.185637e-03;\t val:7.374029e-03;0.993135;6.147285e-03; test:7.374029e-03;0.993135;6.147285e-03;Speed:40\n",
    "epoch: 31;\t train:7.884770e-03;0.993860;6.151051e-03;\t val:7.348566e-03;0.992863;6.131436e-03; test:7.348566e-03;0.992863;6.131436e-03;Speed:40\n",
    "epoch: 32;\t train:7.850924e-03;0.993854;6.172373e-03;\t val:7.311112e-03;0.992946;6.127407e-03; test:7.311112e-03;0.992946;6.127407e-03;Speed:41\n",
    "epoch: 33;\t train:7.759298e-03;0.993889;6.123039e-03;\t val:7.289164e-03;0.993003;6.124550e-03; test:7.289164e-03;0.993003;6.124550e-03;Speed:40\n",
    "epoch: 34;\t train:7.702364e-03;0.993926;6.074941e-03;\t val:7.262225e-03;0.992939;6.117056e-03; test:7.262225e-03;0.992939;6.117056e-03;Speed:40\n",
    "epoch: 35;\t train:7.704896e-03;0.993897;6.103479e-03;\t val:7.228228e-03;0.993076;6.115493e-03; test:7.228228e-03;0.993076;6.115493e-03;Speed:40\n",
    "epoch: 36;\t train:7.649504e-03;0.993939;6.073239e-03;\t val:7.208826e-03;0.992962;6.108478e-03; test:7.208826e-03;0.992962;6.108478e-03;Speed:39\n",
    "epoch: 37;\t train:7.633490e-03;0.993943;6.073017e-03;\t val:7.194602e-03;0.992867;6.099143e-03; test:7.194602e-03;0.992867;6.099143e-03;Speed:40\n",
    "epoch: 38;\t train:7.662425e-03;0.993894;6.126618e-03;\t val:7.167641e-03;0.992961;6.096784e-03; test:7.167641e-03;0.992961;6.096784e-03;Speed:40\n",
    "epoch: 39;\t train:7.665797e-03;0.993892;6.110212e-03;\t val:7.159119e-03;0.992822;6.086831e-03; test:7.159119e-03;0.992822;6.086831e-03;Speed:40\n",
    "epoch: 40;\t train:7.635562e-03;0.993896;6.117155e-03;\t val:7.129638e-03;0.992965;6.086096e-03; test:7.129638e-03;0.992965;6.086096e-03;Speed:40\n",
    "epoch: 41;\t train:7.607177e-03;0.993903;6.113161e-03;\t val:7.112128e-03;0.992867;6.078559e-03; test:7.112128e-03;0.992867;6.078559e-03;Speed:40\n",
    "epoch: 42;\t train:7.501025e-03;0.993976;6.032475e-03;\t val:7.096339e-03;0.992759;6.073490e-03; test:7.096339e-03;0.992759;6.073490e-03;Speed:40\n",
    "epoch: 43;\t train:7.621433e-03;0.993859;6.148585e-03;\t val:7.076478e-03;0.992819;6.069315e-03; test:7.076478e-03;0.992819;6.069315e-03;Speed:40\n",
    "epoch: 44;\t train:7.608746e-03;0.993865;6.158967e-03;\t val:7.059142e-03;0.992865;6.067057e-03; test:7.059142e-03;0.992865;6.067057e-03;Speed:40\n",
    "epoch: 45;\t train:7.549678e-03;0.993891;6.115454e-03;\t val:7.036726e-03;0.992847;6.062885e-03; test:7.036726e-03;0.992847;6.062885e-03;Speed:40\n",
    "epoch: 46;\t train:7.541899e-03;0.993875;6.123999e-03;\t val:7.033293e-03;0.992717;6.055468e-03; test:7.033293e-03;0.992717;6.055468e-03;Speed:40\n",
    "epoch: 47;\t train:7.547598e-03;0.993876;6.100451e-03;\t val:7.016356e-03;0.992732;6.050787e-03; test:7.016356e-03;0.992732;6.050787e-03;Speed:40\n",
    "epoch: 48;\t train:7.476700e-03;0.993919;6.079110e-03;\t val:6.991134e-03;0.992822;6.049026e-03; test:6.991134e-03;0.992822;6.049026e-03;Speed:40\n",
    "epoch: 49;\t train:7.475222e-03;0.993913;6.092777e-03;\t val:6.978416e-03;0.992794;6.042495e-03; test:6.978416e-03;0.992794;6.042495e-03;Speed:40\n",
    "epoch: 50;\t train:7.434025e-03;0.993944;6.056409e-03;\t val:6.964499e-03;0.992880;6.039409e-03; test:6.964499e-03;0.992880;6.039409e-03;Speed:40\n",
    "epoch: 51;\t train:7.472601e-03;0.993890;6.111720e-03;\t val:6.949925e-03;0.992864;6.038455e-03; test:6.949925e-03;0.992864;6.038455e-03;Speed:40\n",
    "epoch: 52;\t train:7.426583e-03;0.993897;6.080738e-03;\t val:6.936628e-03;0.992730;6.029777e-03; test:6.936628e-03;0.992730;6.029777e-03;Speed:40\n",
    "epoch: 53;\t train:7.401999e-03;0.993919;6.065011e-03;\t val:6.911806e-03;0.992952;6.032443e-03; test:6.911806e-03;0.992952;6.032443e-03;Speed:40\n",
    "epoch: 54;\t train:7.425821e-03;0.993904;6.097063e-03;\t val:6.898795e-03;0.992998;6.030235e-03; test:6.898795e-03;0.992998;6.030235e-03;Speed:40\n",
    "epoch: 55;\t train:7.392646e-03;0.993933;6.048224e-03;\t val:6.900571e-03;0.992659;6.016790e-03; test:6.900571e-03;0.992659;6.016790e-03;Speed:40\n",
    "epoch: 56;\t train:7.420126e-03;0.993875;6.111210e-03;\t val:6.884966e-03;0.992695;6.014874e-03; test:6.884966e-03;0.992695;6.014874e-03;Speed:40\n",
    "epoch: 57;\t train:7.353380e-03;0.993925;6.058267e-03;\t val:6.866312e-03;0.992820;6.015079e-03; test:6.866312e-03;0.992820;6.015079e-03;Speed:40\n",
    "epoch: 58;\t train:7.361226e-03;0.993898;6.083433e-03;\t val:6.866978e-03;0.992642;6.007501e-03; test:6.866978e-03;0.992642;6.007501e-03;Speed:41\n",
    "epoch: 59;\t train:7.358298e-03;0.993912;6.084402e-03;\t val:6.846380e-03;0.992923;6.011905e-03; test:6.846380e-03;0.992923;6.011905e-03;Speed:41\n",
    "epoch: 60;\t train:7.305624e-03;0.993945;6.032217e-03;\t val:6.832483e-03;0.992743;6.001640e-03; test:6.832483e-03;0.992743;6.001640e-03;Speed:40\n",
    "epoch: 61;\t train:7.385527e-03;0.993858;6.121610e-03;\t val:6.822077e-03;0.992926;6.005863e-03; test:6.822077e-03;0.992926;6.005863e-03;Speed:40\n",
    "epoch: 62;\t train:7.368079e-03;0.993882;6.104236e-03;\t val:6.813836e-03;0.992866;6.001690e-03; test:6.813836e-03;0.992866;6.001690e-03;Speed:41\n",
    "epoch: 63;\t train:7.334082e-03;0.993900;6.064527e-03;\t val:6.809861e-03;0.992565;5.987646e-03; test:6.809861e-03;0.992565;5.987646e-03;Speed:40\n",
    "epoch: 64;\t train:7.286951e-03;0.993908;6.046847e-03;\t val:6.791454e-03;0.992729;5.988769e-03; test:6.791454e-03;0.992729;5.988769e-03;Speed:40\n",
    "epoch: 65;\t train:7.309351e-03;0.993896;6.081405e-03;\t val:6.788294e-03;0.992652;5.984942e-03; test:6.788294e-03;0.992652;5.984942e-03;Speed:40\n",
    "epoch: 66;\t train:7.209399e-03;0.993971;5.993608e-03;\t val:6.775340e-03;0.992726;5.982807e-03; test:6.775340e-03;0.992726;5.982807e-03;Speed:40\n",
    "epoch: 67;\t train:7.238864e-03;0.993958;6.029158e-03;\t val:6.765372e-03;0.992709;5.980921e-03; test:6.765372e-03;0.992709;5.980921e-03;Speed:40\n",
    "epoch: 68;\t train:7.207613e-03;0.993976;6.004861e-03;\t val:6.767951e-03;0.992459;5.970092e-03; test:6.767951e-03;0.992459;5.970092e-03;Speed:40\n",
    "epoch: 69;\t train:7.317545e-03;0.993847;6.109607e-03;\t val:6.747733e-03;0.992712;5.974876e-03; test:6.747733e-03;0.992712;5.974876e-03;Speed:40\n",
    "epoch: 70;\t train:7.246620e-03;0.993905;6.057763e-03;\t val:6.752350e-03;0.992400;5.964432e-03; test:6.752350e-03;0.992400;5.964432e-03;Speed:40\n",
    "epoch: 71;\t train:7.292309e-03;0.993906;6.069680e-03;\t val:6.744075e-03;0.992392;5.959014e-03; test:6.744075e-03;0.992392;5.959014e-03;Speed:40\n",
    "epoch: 72;\t train:7.267778e-03;0.993885;6.079385e-03;\t val:6.711879e-03;0.992745;5.965037e-03; test:6.711879e-03;0.992745;5.965037e-03;Speed:40\n",
    "epoch: 73;\t train:7.170345e-03;0.993965;6.000010e-03;\t val:6.709798e-03;0.992691;5.961530e-03; test:6.709798e-03;0.992691;5.961530e-03;Speed:40\n",
    "epoch: 74;\t train:7.196446e-03;0.993913;6.035518e-03;\t val:6.699409e-03;0.992689;5.960859e-03; test:6.699409e-03;0.992689;5.960859e-03;Speed:40\n",
    "epoch: 75;\t train:7.159769e-03;0.993927;6.011308e-03;\t val:6.696400e-03;0.992682;5.957167e-03; test:6.696400e-03;0.992682;5.957167e-03;Speed:40\n",
    "epoch: 76;\t train:7.176945e-03;0.993920;6.035199e-03;\t val:6.676882e-03;0.992720;5.955221e-03; test:6.676882e-03;0.992720;5.955221e-03;Speed:40\n",
    "epoch: 77;\t train:7.147350e-03;0.993938;6.011424e-03;\t val:6.675314e-03;0.992643;5.950407e-03; test:6.675314e-03;0.992643;5.950407e-03;Speed:40\n",
    "epoch: 78;\t train:7.188860e-03;0.993913;6.043876e-03;\t val:6.668028e-03;0.992617;5.948151e-03; test:6.668028e-03;0.992617;5.948151e-03;Speed:40\n",
    "epoch: 79;\t train:7.165831e-03;0.993935;6.005026e-03;\t val:6.665958e-03;0.992476;5.938261e-03; test:6.665958e-03;0.992476;5.938261e-03;Speed:40\n",
    "epoch: 80;\t train:7.274329e-03;0.993839;6.136664e-03;\t val:6.638731e-03;0.992828;5.947841e-03; test:6.638731e-03;0.992828;5.947841e-03;Speed:40\n",
    "epoch: 81;\t train:7.127312e-03;0.993937;6.007542e-03;\t val:6.634752e-03;0.992757;5.943384e-03; test:6.634752e-03;0.992757;5.943384e-03;Speed:40\n",
    "epoch: 82;\t train:7.173822e-03;0.993906;6.055845e-03;\t val:6.628759e-03;0.992735;5.940622e-03; test:6.628759e-03;0.992735;5.940622e-03;Speed:40\n",
    "epoch: 83;\t train:7.179928e-03;0.993916;6.057618e-03;\t val:6.625833e-03;0.992608;5.933399e-03; test:6.625833e-03;0.992608;5.933399e-03;Speed:40\n",
    "epoch: 84;\t train:7.190321e-03;0.993861;6.085529e-03;\t val:6.622126e-03;0.992829;5.938581e-03; test:6.622126e-03;0.992829;5.938581e-03;Speed:40\n",
    "epoch: 85;\t train:7.065246e-03;0.993953;5.975690e-03;\t val:6.612321e-03;0.992602;5.927234e-03; test:6.612321e-03;0.992602;5.927234e-03;Speed:40\n",
    "epoch: 86;\t train:7.070848e-03;0.993965;5.981330e-03;\t val:6.609881e-03;0.992551;5.922164e-03; test:6.609881e-03;0.992551;5.922164e-03;Speed:40\n",
    "epoch: 87;\t train:7.134682e-03;0.993925;6.016506e-03;\t val:6.590801e-03;0.992841;5.931182e-03; test:6.590801e-03;0.992841;5.931182e-03;Speed:40\n",
    "epoch: 88;\t train:7.075289e-03;0.993939;5.988898e-03;\t val:6.592703e-03;0.992571;5.920212e-03; test:6.592703e-03;0.992571;5.920212e-03;Speed:40\n",
    "epoch: 89;\t train:7.133218e-03;0.993902;6.054555e-03;\t val:6.589480e-03;0.992482;5.915825e-03; test:6.589480e-03;0.992482;5.915825e-03;Speed:41\n",
    "epoch: 90;\t train:7.094846e-03;0.993920;6.016837e-03;\t val:6.579505e-03;0.992559;5.914198e-03; test:6.579505e-03;0.992559;5.914198e-03;Speed:40\n",
    "epoch: 91;\t train:7.116502e-03;0.993919;6.036556e-03;\t val:6.569907e-03;0.992668;5.916034e-03; test:6.569907e-03;0.992668;5.916034e-03;Speed:40\n",
    "epoch: 92;\t train:7.103782e-03;0.993885;6.035771e-03;\t val:6.559915e-03;0.992804;5.919072e-03; test:6.559915e-03;0.992804;5.919072e-03;Speed:40\n",
    "epoch: 93;\t train:7.106342e-03;0.993880;6.051410e-03;\t val:6.557655e-03;0.992678;5.913768e-03; test:6.557655e-03;0.992678;5.913768e-03;Speed:40\n",
    "epoch: 94;\t train:7.074846e-03;0.993899;6.022931e-03;\t val:6.550589e-03;0.992658;5.912390e-03; test:6.550589e-03;0.992658;5.912390e-03;Speed:41\n",
    "epoch: 95;\t train:7.100173e-03;0.993909;6.029629e-03;\t val:6.540688e-03;0.992680;5.909632e-03; test:6.540688e-03;0.992680;5.909632e-03;Speed:40\n",
    "epoch: 96;\t train:7.072904e-03;0.993911;6.031712e-03;\t val:6.545513e-03;0.992457;5.899425e-03; test:6.545513e-03;0.992457;5.899425e-03;Speed:40\n",
    "epoch: 97;\t train:7.050988e-03;0.993927;6.006417e-03;\t val:6.521956e-03;0.992933;5.913114e-03; test:6.521956e-03;0.992933;5.913114e-03;Speed:40\n",
    "epoch: 98;\t train:7.019179e-03;0.993929;5.988759e-03;\t val:6.541510e-03;0.992271;5.888466e-03; test:6.541510e-03;0.992271;5.888466e-03;Speed:40\n",
    "epoch: 99;\t train:7.045711e-03;0.993929;6.003491e-03;\t val:6.511937e-03;0.992817;5.902246e-03; test:6.511937e-03;0.992817;5.902246e-03;Speed:40\n",
    "epoch:100;\t train:7.056459e-03;0.993905;6.029734e-03;\t val:6.499890e-03;0.992764;5.898652e-03; test:6.499890e-03;0.992764;5.898652e-03;Speed:41\n",
    "epoch:101;\t train:7.005169e-03;0.993948;5.981248e-03;\t val:6.503215e-03;0.992501;5.887221e-03; test:6.503215e-03;0.992501;5.887221e-03;Speed:40\n",
    "epoch:102;\t train:7.023081e-03;0.993930;6.004097e-03;\t val:6.495017e-03;0.992550;5.886635e-03; test:6.495017e-03;0.992550;5.886635e-03;Speed:40\n",
    "epoch:103;\t train:7.076046e-03;0.993898;6.028742e-03;\t val:6.500007e-03;0.992470;5.884780e-03; test:6.500007e-03;0.992470;5.884780e-03;Speed:40\n",
    "epoch:104;\t train:7.044996e-03;0.993900;6.031934e-03;\t val:6.476945e-03;0.992797;5.892981e-03; test:6.476945e-03;0.992797;5.892981e-03;Speed:40\n",
    "epoch:105;\t train:7.046965e-03;0.993893;6.034258e-03;\t val:6.468999e-03;0.992888;5.894326e-03; test:6.468999e-03;0.992888;5.894326e-03;Speed:41\n",
    "epoch:106;\t train:6.998417e-03;0.993936;5.999576e-03;\t val:6.469620e-03;0.992637;5.882284e-03; test:6.469620e-03;0.992637;5.882284e-03;Speed:40\n",
    "epoch:107;\t train:7.006690e-03;0.993930;5.999891e-03;\t val:6.461083e-03;0.992834;5.887215e-03; test:6.461083e-03;0.992834;5.887215e-03;Speed:40\n",
    "epoch:108;\t train:6.971671e-03;0.993928;5.983606e-03;\t val:6.461241e-03;0.992488;5.873786e-03; test:6.461241e-03;0.992488;5.873786e-03;Speed:40\n",
    "epoch:109;\t train:6.937354e-03;0.993973;5.948716e-03;\t val:6.453757e-03;0.992576;5.874537e-03; test:6.453757e-03;0.992576;5.874537e-03;Speed:40\n",
    "epoch:110;\t train:6.991553e-03;0.993899;6.005444e-03;\t val:6.440235e-03;0.992737;5.879047e-03; test:6.440235e-03;0.992737;5.879047e-03;Speed:41\n",
    "epoch:111;\t train:6.981076e-03;0.993920;5.982894e-03;\t val:6.441640e-03;0.992469;5.867381e-03; test:6.441640e-03;0.992469;5.867381e-03;Speed:40\n",
    "epoch:112;\t train:6.949118e-03;0.993942;5.973387e-03;\t val:6.428936e-03;0.992741;5.874080e-03; test:6.428936e-03;0.992741;5.874080e-03;Speed:40\n",
    "epoch:113;\t train:7.025065e-03;0.993865;6.045345e-03;\t val:6.427642e-03;0.992951;5.882707e-03; test:6.427642e-03;0.992951;5.882707e-03;Speed:40\n",
    "epoch:114;\t train:6.980843e-03;0.993898;6.010246e-03;\t val:6.423013e-03;0.992693;5.868635e-03; test:6.423013e-03;0.992693;5.868635e-03;Speed:40\n",
    "epoch:115;\t train:6.936724e-03;0.993930;5.970441e-03;\t val:6.428150e-03;0.992498;5.861987e-03; test:6.428150e-03;0.992498;5.861987e-03;Speed:40\n",
    "epoch:116;\t train:6.887212e-03;0.993977;5.924555e-03;\t val:6.425258e-03;0.992358;5.852926e-03; test:6.425258e-03;0.992358;5.852926e-03;Speed:40\n",
    "epoch:117;\t train:6.961330e-03;0.993918;5.994450e-03;\t val:6.405996e-03;0.992692;5.861360e-03; test:6.405996e-03;0.992692;5.861360e-03;Speed:40\n",
    "epoch:118;\t train:6.970039e-03;0.993917;6.006331e-03;\t val:6.398384e-03;0.992680;5.858241e-03; test:6.398384e-03;0.992680;5.858241e-03;Speed:40\n",
    "epoch:119;\t train:7.014331e-03;0.993899;6.031228e-03;\t val:6.400680e-03;0.992579;5.854684e-03; test:6.400680e-03;0.992579;5.854684e-03;Speed:40\n",
    "epoch:120;\t train:6.899278e-03;0.993972;5.942657e-03;\t val:6.383536e-03;0.992907;5.863888e-03; test:6.383536e-03;0.992907;5.863888e-03;Speed:41\n",
    "epoch:121;\t train:6.958605e-03;0.993896;6.016230e-03;\t val:6.382863e-03;0.992807;5.859303e-03; test:6.382863e-03;0.992807;5.859303e-03;Speed:40\n",
    "epoch:122;\t train:6.954855e-03;0.993900;6.006061e-03;\t val:6.383534e-03;0.992641;5.852786e-03; test:6.383534e-03;0.992641;5.852786e-03;Speed:40\n",
    "epoch:123;\t train:6.932193e-03;0.993929;5.988231e-03;\t val:6.378334e-03;0.992726;5.853097e-03; test:6.378334e-03;0.992726;5.853097e-03;Speed:40\n",
    "epoch:124;\t train:6.941537e-03;0.993891;5.999370e-03;\t val:6.394863e-03;0.992176;5.834690e-03; test:6.394863e-03;0.992176;5.834690e-03;Speed:40\n",
    "epoch:125;\t train:6.983686e-03;0.993866;6.035207e-03;\t val:6.379317e-03;0.992373;5.837518e-03; test:6.379317e-03;0.992373;5.837518e-03;Speed:40\n",
    "epoch:126;\t train:6.938030e-03;0.993912;5.998639e-03;\t val:6.362378e-03;0.992644;5.844885e-03; test:6.362378e-03;0.992644;5.844885e-03;Speed:40\n",
    "epoch:127;\t train:6.975316e-03;0.993889;6.021003e-03;\t val:6.358208e-03;0.992575;5.839832e-03; test:6.358208e-03;0.992575;5.839832e-03;Speed:40\n",
    "epoch:128;\t train:6.924371e-03;0.993898;6.004311e-03;\t val:6.363801e-03;0.992556;5.840466e-03; test:6.363801e-03;0.992556;5.840466e-03;Speed:40\n",
    "epoch:129;\t train:6.873670e-03;0.993954;5.960226e-03;\t val:6.345374e-03;0.992884;5.848225e-03; test:6.345374e-03;0.992884;5.848225e-03;Speed:40\n",
    "epoch:130;\t train:6.915820e-03;0.993920;5.991590e-03;\t val:6.349467e-03;0.992568;5.833747e-03; test:6.349467e-03;0.992568;5.833747e-03;Speed:40\n",
    "epoch:131;\t train:6.952298e-03;0.993879;6.040428e-03;\t val:6.347655e-03;0.992685;5.838966e-03; test:6.347655e-03;0.992685;5.838966e-03;Speed:41\n",
    "epoch:132;\t train:6.895958e-03;0.993921;5.983869e-03;\t val:6.333517e-03;0.992780;5.839472e-03; test:6.333517e-03;0.992780;5.839472e-03;Speed:41\n",
    "epoch:133;\t train:6.912003e-03;0.993923;5.997136e-03;\t val:6.326452e-03;0.992804;5.838915e-03; test:6.326452e-03;0.992804;5.838915e-03;Speed:40\n",
    "epoch:134;\t train:6.862123e-03;0.993930;5.959975e-03;\t val:6.332823e-03;0.992598;5.830509e-03; test:6.332823e-03;0.992598;5.830509e-03;Speed:41\n",
    "epoch:135;\t train:6.881043e-03;0.993950;5.947832e-03;\t val:6.317813e-03;0.992747;5.833954e-03; test:6.317813e-03;0.992747;5.833954e-03;Speed:40\n",
    "epoch:136;\t train:6.851800e-03;0.993932;5.955047e-03;\t val:6.323595e-03;0.992534;5.824517e-03; test:6.323595e-03;0.992534;5.824517e-03;Speed:40\n",
    "epoch:137;\t train:6.874014e-03;0.993933;5.981453e-03;\t val:6.319158e-03;0.992917;5.842361e-03; test:6.319158e-03;0.992917;5.842361e-03;Speed:39\n",
    "epoch:138;\t train:6.841198e-03;0.993937;5.943579e-03;\t val:6.314989e-03;0.992771;5.832556e-03; test:6.314989e-03;0.992771;5.832556e-03;Speed:40\n",
    "epoch:139;\t train:6.871525e-03;0.993904;5.982567e-03;\t val:6.307117e-03;0.992876;5.838042e-03; test:6.307117e-03;0.992876;5.838042e-03;Speed:40\n",
    "epoch:140;\t train:6.912452e-03;0.993902;6.014166e-03;\t val:6.302100e-03;0.992771;5.833859e-03; test:6.302100e-03;0.992771;5.833859e-03;Speed:40\n",
    "epoch:141;\t train:6.885571e-03;0.993878;5.996022e-03;\t val:6.306354e-03;0.992863;5.834960e-03; test:6.306354e-03;0.992863;5.834960e-03;Speed:40\n",
    "epoch:142;\t train:6.887034e-03;0.993889;5.996398e-03;\t val:6.291761e-03;0.993049;5.842495e-03; test:6.291761e-03;0.993049;5.842495e-03;Speed:40\n",
    "epoch:143;\t train:6.872580e-03;0.993910;5.987704e-03;\t val:6.286227e-03;0.992937;5.833721e-03; test:6.286227e-03;0.992937;5.833721e-03;Speed:40\n",
    "epoch:144;\t train:6.919725e-03;0.993885;6.005545e-03;\t val:6.282377e-03;0.992994;5.835179e-03; test:6.282377e-03;0.992994;5.835179e-03;Speed:40\n",
    "epoch:145;\t train:6.873132e-03;0.993913;5.991776e-03;\t val:6.284660e-03;0.992663;5.821172e-03; test:6.284660e-03;0.992663;5.821172e-03;Speed:40\n",
    "epoch:146;\t train:6.832617e-03;0.993943;5.952774e-03;\t val:6.275640e-03;0.992898;5.826884e-03; test:6.275640e-03;0.992898;5.826884e-03;Speed:40\n",
    "epoch:147;\t train:6.863938e-03;0.993889;5.975269e-03;\t val:6.271572e-03;0.992776;5.821131e-03; test:6.271572e-03;0.992776;5.821131e-03;Speed:40\n",
    "epoch:148;\t train:6.852818e-03;0.993910;5.982439e-03;\t val:6.260792e-03;0.992919;5.823930e-03; test:6.260792e-03;0.992919;5.823930e-03;Speed:40\n",
    "epoch:149;\t train:6.881422e-03;0.993865;6.011585e-03;\t val:6.260222e-03;0.992757;5.816310e-03; test:6.260222e-03;0.992757;5.816310e-03;Speed:40\n",
    "epoch:150;\t train:6.819789e-03;0.993919;5.965015e-03;\t val:6.252889e-03;0.992895;5.821726e-03; test:6.252889e-03;0.992895;5.821726e-03;Speed:40\n",
    "epoch:151;\t train:6.853069e-03;0.993901;5.990856e-03;\t val:6.254568e-03;0.993058;5.828845e-03; test:6.254568e-03;0.993058;5.828845e-03;Speed:40\n",
    "epoch:152;\t train:6.883994e-03;0.993897;5.974851e-03;\t val:6.244023e-03;0.992855;5.817008e-03; test:6.244023e-03;0.992855;5.817008e-03;Speed:40\n",
    "epoch:153;\t train:6.854694e-03;0.993897;5.989494e-03;\t val:6.242216e-03;0.992955;5.818147e-03; test:6.242216e-03;0.992955;5.818147e-03;Speed:40\n",
    "epoch:154;\t train:6.802555e-03;0.993940;5.938766e-03;\t val:6.229790e-03;0.992902;5.813427e-03; test:6.229790e-03;0.992902;5.813427e-03;Speed:40\n",
    "epoch:155;\t train:6.828360e-03;0.993920;5.970519e-03;\t val:6.230251e-03;0.992936;5.812848e-03; test:6.230251e-03;0.992936;5.812848e-03;Speed:40\n",
    "epoch:156;\t train:6.865461e-03;0.993870;6.013015e-03;\t val:6.244240e-03;0.992517;5.795602e-03; test:6.244240e-03;0.992517;5.795602e-03;Speed:40\n",
    "epoch:157;\t train:6.816935e-03;0.993919;5.971947e-03;\t val:6.229187e-03;0.992894;5.808777e-03; test:6.229187e-03;0.992894;5.808777e-03;Speed:40\n",
    "epoch:158;\t train:6.863230e-03;0.993872;6.003452e-03;\t val:6.229071e-03;0.992941;5.812940e-03; test:6.229071e-03;0.992941;5.812940e-03;Speed:40\n",
    "epoch:159;\t train:6.757871e-03;0.993958;5.909636e-03;\t val:6.240139e-03;0.992342;5.787253e-03; test:6.240139e-03;0.992342;5.787253e-03;Speed:40\n",
    "epoch:160;\t train:6.857288e-03;0.993911;5.982132e-03;\t val:6.219093e-03;0.992845;5.804937e-03; test:6.219093e-03;0.992845;5.804937e-03;Speed:40\n",
    "epoch:161;\t train:6.811115e-03;0.993920;5.955153e-03;\t val:6.211681e-03;0.992952;5.809058e-03; test:6.211681e-03;0.992952;5.809058e-03;Speed:40\n",
    "epoch:162;\t train:6.856450e-03;0.993865;6.014866e-03;\t val:6.222558e-03;0.992697;5.797428e-03; test:6.222558e-03;0.992697;5.797428e-03;Speed:40\n",
    "epoch:163;\t train:6.784537e-03;0.993939;5.941940e-03;\t val:6.209480e-03;0.992717;5.794711e-03; test:6.209480e-03;0.992717;5.794711e-03;Speed:40\n",
    "epoch:164;\t train:6.745260e-03;0.993962;5.917723e-03;\t val:6.208138e-03;0.992963;5.805551e-03; test:6.208138e-03;0.992963;5.805551e-03;Speed:40\n",
    "epoch:165;\t train:6.803493e-03;0.993898;5.968152e-03;\t val:6.202438e-03;0.992876;5.801338e-03; test:6.202438e-03;0.992876;5.801338e-03;Speed:40\n",
    "epoch:166;\t train:6.847511e-03;0.993876;6.008526e-03;\t val:6.198978e-03;0.992775;5.792508e-03; test:6.198978e-03;0.992775;5.792508e-03;Speed:40\n",
    "epoch:167;\t train:6.832559e-03;0.993877;6.000724e-03;\t val:6.192137e-03;0.993098;5.807188e-03; test:6.192137e-03;0.993098;5.807188e-03;Speed:40\n",
    "epoch:168;\t train:6.797509e-03;0.993944;5.937563e-03;\t val:6.189236e-03;0.992719;5.787695e-03; test:6.189236e-03;0.992719;5.787695e-03;Speed:40\n",
    "epoch:169;\t train:6.886583e-03;0.993829;6.054745e-03;\t val:6.195080e-03;0.992593;5.780751e-03; test:6.195080e-03;0.992593;5.780751e-03;Speed:40\n",
    "epoch:170;\t train:6.754939e-03;0.993949;5.923172e-03;\t val:6.181503e-03;0.992957;5.797588e-03; test:6.181503e-03;0.992957;5.797588e-03;Speed:40\n",
    "epoch:171;\t train:6.824077e-03;0.993868;6.001766e-03;\t val:6.188183e-03;0.992834;5.790442e-03; test:6.188183e-03;0.992834;5.790442e-03;Speed:41\n",
    "epoch:172;\t train:6.789923e-03;0.993903;5.967109e-03;\t val:6.188623e-03;0.992612;5.779841e-03; test:6.188623e-03;0.992612;5.779841e-03;Speed:40\n",
    "epoch:173;\t train:6.763968e-03;0.993900;5.938311e-03;\t val:6.175711e-03;0.992742;5.780942e-03; test:6.175711e-03;0.992742;5.780942e-03;Speed:40\n",
    "epoch:174;\t train:6.815460e-03;0.993877;5.989906e-03;\t val:6.175012e-03;0.992715;5.782257e-03; test:6.175012e-03;0.992715;5.782257e-03;Speed:40\n",
    "epoch:175;\t train:6.756441e-03;0.993933;5.938058e-03;\t val:6.164689e-03;0.992848;5.785043e-03; test:6.164689e-03;0.992848;5.785043e-03;Speed:40\n",
    "epoch:176;\t train:6.817364e-03;0.993892;5.977413e-03;\t val:6.163938e-03;0.992845;5.786482e-03; test:6.163938e-03;0.992845;5.786482e-03;Speed:40\n",
    "epoch:177;\t train:6.830505e-03;0.993883;6.015701e-03;\t val:6.168032e-03;0.992761;5.779655e-03; test:6.168032e-03;0.992761;5.779655e-03;Speed:40\n",
    "epoch:178;\t train:6.731283e-03;0.993936;5.924685e-03;\t val:6.162908e-03;0.992764;5.778587e-03; test:6.162908e-03;0.992764;5.778587e-03;Speed:40\n",
    "epoch:179;\t train:6.824373e-03;0.993859;6.014499e-03;\t val:6.164587e-03;0.992704;5.775214e-03; test:6.164587e-03;0.992704;5.775214e-03;Speed:40\n",
    "epoch:180;\t train:6.839604e-03;0.993840;6.031805e-03;\t val:6.155729e-03;0.992892;5.783746e-03; test:6.155729e-03;0.992892;5.783746e-03;Speed:40\n",
    "epoch:181;\t train:6.776217e-03;0.993886;5.970677e-03;\t val:6.159050e-03;0.992600;5.768833e-03; test:6.159050e-03;0.992600;5.768833e-03;Speed:40\n",
    "epoch:182;\t train:6.760895e-03;0.993918;5.948301e-03;\t val:6.141235e-03;0.993041;5.786313e-03; test:6.141235e-03;0.993041;5.786313e-03;Speed:40\n",
    "epoch:183;\t train:6.818099e-03;0.993846;6.004380e-03;\t val:6.135062e-03;0.992792;5.775615e-03; test:6.135062e-03;0.992792;5.775615e-03;Speed:41\n",
    "epoch:184;\t train:6.787570e-03;0.993906;5.951527e-03;\t val:6.138546e-03;0.993024;5.784996e-03; test:6.138546e-03;0.993024;5.784996e-03;Speed:40\n",
    "epoch:185;\t train:6.811818e-03;0.993859;6.008224e-03;\t val:6.136113e-03;0.993003;5.781546e-03; test:6.136113e-03;0.993003;5.781546e-03;Speed:40\n",
    "epoch:186;\t train:6.756543e-03;0.993892;5.955420e-03;\t val:6.139744e-03;0.992635;5.765311e-03; test:6.139744e-03;0.992635;5.765311e-03;Speed:40\n",
    "epoch:187;\t train:6.718088e-03;0.993927;5.925944e-03;\t val:6.142104e-03;0.992526;5.759662e-03; test:6.142104e-03;0.992526;5.759662e-03;Speed:40\n",
    "epoch:188;\t train:6.792973e-03;0.993864;5.990984e-03;\t val:6.128818e-03;0.992887;5.774146e-03; test:6.128818e-03;0.992887;5.774146e-03;Speed:40\n",
    "epoch:189;\t train:6.714555e-03;0.993931;5.922615e-03;\t val:6.131057e-03;0.992569;5.758756e-03; test:6.131057e-03;0.992569;5.758756e-03;Speed:40\n",
    "epoch:190;\t train:6.745194e-03;0.993906;5.960652e-03;\t val:6.127154e-03;0.992919;5.771644e-03; test:6.127154e-03;0.992919;5.771644e-03;Speed:40\n",
    "epoch:191;\t train:6.766998e-03;0.993890;5.971332e-03;\t val:6.116919e-03;0.993061;5.778616e-03; test:6.116919e-03;0.993061;5.778616e-03;Speed:40\n",
    "epoch:192;\t train:6.743290e-03;0.993940;5.920914e-03;\t val:6.112772e-03;0.992981;5.770793e-03; test:6.112772e-03;0.992981;5.770793e-03;Speed:40\n",
    "epoch:193;\t train:6.674937e-03;0.993966;5.894213e-03;\t val:6.115874e-03;0.992879;5.768976e-03; test:6.115874e-03;0.992879;5.768976e-03;Speed:40\n",
    "epoch:194;\t train:6.686798e-03;0.993960;5.893718e-03;\t val:6.116081e-03;0.992815;5.762825e-03; test:6.116081e-03;0.992815;5.762825e-03;Speed:40\n",
    "epoch:195;\t train:6.737670e-03;0.993916;5.952798e-03;\t val:6.122465e-03;0.992546;5.751849e-03; test:6.122465e-03;0.992546;5.751849e-03;Speed:40\n",
    "epoch:196;\t train:6.726228e-03;0.993922;5.946609e-03;\t val:6.110551e-03;0.992686;5.752923e-03; test:6.110551e-03;0.992686;5.752923e-03;Speed:40\n",
    "epoch:197;\t train:6.768748e-03;0.993887;5.987734e-03;\t val:6.112893e-03;0.992613;5.750970e-03; test:6.112893e-03;0.992613;5.750970e-03;Speed:39\n",
    "epoch:198;\t train:6.758951e-03;0.993864;5.980339e-03;\t val:6.096713e-03;0.993070;5.771220e-03; test:6.096713e-03;0.993070;5.771220e-03;Speed:40\n",
    "epoch:199;\t train:6.660893e-03;0.993967;5.888131e-03;\t val:6.093632e-03;0.992923;5.760820e-03; test:6.093632e-03;0.992923;5.760820e-03;Speed:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = test_dataset[13]\n",
    "test_image2, test_label2 = test_transform(test_image, test_label)\n",
    "test_image2 = nd.expand_dims(test_image2,0)\n",
    "print('tensor shape:', test_image2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, cls_preds, box_preds = net(test_image2.as_in_context(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert predictions to real object detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxDetection\n",
    "cls_probs = nd.SoftmaxActivation(nd.transpose(cls_preds, (0, 2, 1)), mode='channel')\n",
    "output = MultiBoxDetection(cls_prob=cls_probs, loc_pred=box_preds, anchor=anchors, force_suppress=True, clip=True, nms_topk=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('cluster')\n",
    "def display(img, out, thresh=0.5):\n",
    "    import random\n",
    "    import matplotlib as mpl\n",
    "    import numpy as np\n",
    "    mpl.rcParams['figure.figsize'] = (10,10)\n",
    "    img = img.asnumpy()\n",
    "    img = np.transpose(img,(2,3,1,0))\n",
    "    img = np.squeeze(img)\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    for det in out:\n",
    "        cid = int(det[0])\n",
    "        if cid == 0:\n",
    "            continue\n",
    "        score = det[1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        scales = [img.shape[1], img.shape[0]] * 2\n",
    "        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].tolist(), scales)]\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                             edgecolor='red', linewidth=3)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = class_names[cid]\n",
    "        plt.gca().text(xmin, ymin-2, '{:s} {:.3f}'.format(text, score),\n",
    "                       bbox=dict(facecolor='red', alpha=0.5),\n",
    "                       fontsize=12, color='white')\n",
    "\n",
    "display(test_image2, output[0].asnumpy(), thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
