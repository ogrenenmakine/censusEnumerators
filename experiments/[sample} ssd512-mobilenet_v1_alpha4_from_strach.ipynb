{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.contrib.ndarray import MultiBoxPrior\n",
    "from mxnet.gluon.contrib import nn as nn_contrib\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict classes\n",
    "- channel `i*(num_class+1)` store the scores for this box contains only background\n",
    "- channel `i*(num_class+1)+1+j` store the scores for this box contains an object from the *j*-th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "def class_predictor(num_anchors, num_classes):\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict anchor boxes\n",
    "- $t_x = (Y_x - b_x) / b_{width}$\n",
    "- $t_y = (Y_y - b_y) / b_{height}$\n",
    "- $t_{width} = (Y_{width} - b_{width}) / b_{width}$\n",
    "- $t_{height} = (Y_{height} - b_{height}) / b_{height}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_predictor(num_anchors):\n",
    "    return nn.Conv2D(num_anchors * 4, 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage preditions from multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_prediction(pred):\n",
    "    return nd.flatten(nd.transpose(pred, axes=(0, 2, 3, 1)))\n",
    "\n",
    "def concat_predictions(preds):\n",
    "    return nd.concat(*preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_layer(nfilters, stride, expension_constant):\n",
    "    out = nn.HybridSequential()\n",
    "    out.add(nn.Conv2D(nfilters, 3, strides=stride, padding=1, groups=nfilters))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(nfilters*expension_constant, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 0.25\n",
    "num_filters = int(32*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "def s16():\n",
    "    out = nn.HybridSequential()\n",
    "    # conv_0 layer\n",
    "    out.add(nn.Conv2D(num_filters, 3, strides=2, padding=1))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_1 layer\n",
    "    out.add(dp_layer(num_filters, 1, 2))\n",
    "    # conv_2 layer\n",
    "    out.add(dp_layer(num_filters*2, 2, 2))\n",
    "    # conv_3 layer\n",
    "    out.add(dp_layer(num_filters*4, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*4, 3, strides=2, padding=1, groups=num_filters*4))\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def s32():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*8, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_4_layer\n",
    "    out.add(dp_layer(num_filters*8, 1, 1))\n",
    "    # conv_5_layer\n",
    "    out.add(dp_layer(num_filters*8, 1, 1)) \n",
    "    out.add(nn.Conv2D(num_filters*8, 3, strides=2, padding=1, groups=num_filters*8))\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b1():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_6_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16))\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b2():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16))\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b3():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_8_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16))\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def b4():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_9_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*16, 3, strides=2, padding=1, groups=num_filters*16))\n",
    "    out.hybridize()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_model(num_anchors, num_classes):\n",
    "    class_preds = nn.Sequential()\n",
    "    box_preds = nn.Sequential()\n",
    "    \n",
    "    for scale in range(6):\n",
    "        class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "        box_preds.add(box_predictor(num_anchors))\n",
    "    \n",
    "    return s16(), s32(), b1(), b2(), b3(), b4(), class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_forward(x, s16, s32, b1, b2, b3, b4, class_preds, box_preds, sizes, ratios):\n",
    "    default_anchors = []\n",
    "    predicted_boxes = []  \n",
    "    predicted_classes = []\n",
    "\n",
    "    x = s16(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[0], ratios=ratios[0]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[0](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[0](x)))\n",
    "    \n",
    "    x = s32(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[1], ratios=ratios[1]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[1](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[1](x)))\n",
    "    \n",
    "    x = b1(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[2], ratios=ratios[2]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[2](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[2](x)))\n",
    "    \n",
    "    x = b2(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[3], ratios=ratios[3]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[3](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[3](x)))\n",
    "    \n",
    "    x = b3(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[4], ratios=ratios[4]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[4](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[4](x)))\n",
    "    \n",
    "    x = b4(x)\n",
    "    default_anchors.append(MultiBoxPrior(x, sizes=sizes[5], ratios=ratios[5]))\n",
    "    predicted_boxes.append(flatten_prediction(box_preds[5](x)))\n",
    "    predicted_classes.append(flatten_prediction(class_preds[5](x)))\n",
    "\n",
    "    return default_anchors, predicted_classes, predicted_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class SSD(gluon.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(SSD, self).__init__(**kwargs)\n",
    "        self.anchor_sizes = [[0.04, 0.1],[0.1,0.26],[0.26,0.42],[0.42,0.58],[0.58,0.74],[0.74,0.9],[0.9,1.06]]\n",
    "        self.anchor_ratios = [[1, 2, .5]] * 6\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.s16, self.s32, self.b1, self.b2, self.b3, self.b4, self.class_preds, self.box_preds = ssd_model(4, num_classes)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        default_anchors, predicted_classes, predicted_boxes = ssd_forward(x, self.s16, self.s32, self.b1, self.b2, self.b3, self.b4,\n",
    "            self.class_preds, self.box_preds, self.anchor_sizes, self.anchor_ratios)\n",
    "        anchors = concat_predictions(default_anchors)\n",
    "        box_preds = concat_predictions(predicted_boxes)\n",
    "        class_preds = concat_predictions(predicted_classes)\n",
    "        class_preds = nd.reshape(class_preds, shape=(0, -1, self.num_classes + 1))\n",
    "        \n",
    "        return anchors, class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs of SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SSD(2)\n",
    "net.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "#net.load_parameters(\"process/ssd_100.params\",ctx=ctx)\n",
    "x = nd.zeros((1, 3, 512, 512),ctx=ctx)\n",
    "default_anchors, class_predictions, box_predictions = net(x)\n",
    "print('Outputs:', 'anchors', default_anchors.shape, 'class prediction', class_predictions.shape, 'box prediction', box_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.NACDDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train')])\n",
    "test_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import NACDTransform\n",
    "width, height = 512, 512\n",
    "train_transform = NACDTransform.NACDDefaultTransform(width, height, False)\n",
    "test_transform = NACDTransform.NACDDefaultTransform(width, height, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd\n",
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label = test_dataset[0]\n",
    "bboxes = train_label[:, :4]\n",
    "cids = train_label[:, 4:5]\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2, train_label2 = train_transform(train_image, train_label)\n",
    "print('tensor shape:', train_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset.transform(test_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(test_loader):\n",
    "    if ib > 3:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "train_image2 = (train_image2 * 255).clip(0, 255)\n",
    "ax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxTarget\n",
    "def training_targets(default_anchors, class_predicts, labels):\n",
    "    class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))\n",
    "    z = MultiBoxTarget(anchor=default_anchors.as_in_context(mx.cpu()), label=labels.as_in_context(mx.cpu()), cls_pred=class_predicts.as_in_context(mx.cpu()))\n",
    "    box_target = z[0].as_in_context(ctx)  # box offset target for (x, y, width, height)\n",
    "    box_mask = z[1].as_in_context(ctx)  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples\n",
    "    cls_target = z[2].as_in_context(ctx)  # cls_target is an array of labels for all anchors boxes\n",
    "    return box_target, box_mask, cls_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertlbl(y):\n",
    "    mtrx = y[:,:,0:4]\n",
    "    mtrx = mtrx.asnumpy()\n",
    "    mtrx[mtrx == -1] = -width\n",
    "    mtrx = mtrx/512\n",
    "    return mx.nd.concat(nd.expand_dims(y[:,:,4],2),mx.nd.array(mtrx),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(gluon.loss.Loss):\n",
    "    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n",
    "        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label):\n",
    "        output = F.softmax(output)\n",
    "        pt = F.pick(output, label, axis=self._axis, keepdims=True)\n",
    "        loss = -self._alpha * ((1 - pt) ** self._gamma) * F.log(pt)\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)\n",
    "\n",
    "# cls_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "cls_loss = FocalLoss()\n",
    "print(cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothL1Loss(gluon.loss.Loss):\n",
    "    def __init__(self, batch_axis=0, **kwargs):\n",
    "        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label, mask):\n",
    "        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n",
    "        return F.mean(loss, self._batch_axis, exclude=True)\n",
    "\n",
    "box_loss = SmoothL1Loss()\n",
    "print(box_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mxnet import autograd as ag\n",
    "from gluoncv.loss import SSDMultiBoxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop params\n",
    "epochs = 200\n",
    "start_epoch = 1\n",
    "\n",
    "# initialize trainer\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 1e-1, 'wd': 4e-5})\n",
    "\n",
    "# evaluation metrics\n",
    "cls_metric = mx.metric.Accuracy()\n",
    "box_metric = mx.metric.MAE()\n",
    "cls_metric_test = mx.metric.Accuracy()\n",
    "box_metric_test = mx.metric.MAE()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    #train_data.reset()\n",
    "    cls_metric.reset()\n",
    "    box_metric.reset()\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    # iterate through all batch\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            x = batch[0].as_in_context(ctx)\n",
    "            y = batch[1].as_in_context(ctx)\n",
    "            lbl = convertlbl(batch[1])\n",
    "            default_anchors, class_predictions, box_predictions = net(x)\n",
    "            box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "            # losses\n",
    "            loss1 = cls_loss(class_predictions, cls_target)\n",
    "            loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "            # sum all losses\n",
    "            loss = loss1 + loss2\n",
    "            train_loss += nd.sum(loss).asscalar()\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size)\n",
    "        # update metrics\n",
    "        cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "    toc = time.time()\n",
    "    name1_train, val1_train = cls_metric.get()\n",
    "    name2_train, val2_train = box_metric.get()\n",
    "\n",
    "    cls_metric_test.reset()\n",
    "    box_metric_test.reset()\n",
    "    tic = time.time()\n",
    "    test_loss = 0\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        # record gradients\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        y = batch[1].as_in_context(ctx)\n",
    "        lbl = convertlbl(batch[1])\n",
    "        default_anchors, class_predictions, box_predictions = net(x)\n",
    "        box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "        # losses\n",
    "        loss1 = cls_loss(class_predictions, cls_target)\n",
    "        loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "        # sum all losses\n",
    "        loss = loss1 + loss2\n",
    "        test_loss += nd.sum(loss).asscalar()\n",
    "        # update metrics\n",
    "        cls_metric_test.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric_test.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "    toc = time.time()\n",
    "    name1_test, val1_test = cls_metric_test.get()\n",
    "    name2_test, val2_test = box_metric_test.get()\n",
    "    print('epoch:%3d;\\t train:%.6e;%f;%.6e;\\t test:%.6e;%f;%.6e'\n",
    "          %(epoch, train_loss/len(train_dataset), val1_train, val2_train, test_loss/len(test_dataset), val1_test, val2_test))\n",
    "\n",
    "    net.save_parameters('process/ssd_%d.params' % epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch:  1;\t train:1.795796e-02;0.978262;2.012599e-03;\t test:5.510198e-03;0.995936;1.926248e-03\n",
    "epoch:  2;\t train:4.680376e-03;0.996406;1.995839e-03;\t test:3.987878e-03;0.996698;1.959570e-03\n",
    "epoch:  3;\t train:3.748731e-03;0.996933;2.008612e-03;\t test:3.430996e-03;0.997105;2.004376e-03\n",
    "epoch:  4;\t train:3.342686e-03;0.997297;2.002587e-03;\t test:3.072692e-03;0.997477;1.937726e-03\n",
    "epoch:  5;\t train:3.104862e-03;0.997537;1.998712e-03;\t test:2.909768e-03;0.997632;1.966544e-03\n",
    "epoch:  6;\t train:2.944095e-03;0.997684;1.994247e-03;\t test:2.762329e-03;0.997754;1.951525e-03\n",
    "epoch:  7;\t train:2.814816e-03;0.997774;1.983513e-03;\t test:2.677953e-03;0.997817;1.955034e-03\n",
    "epoch:  8;\t train:2.748114e-03;0.997813;1.996710e-03;\t test:2.562142e-03;0.997878;1.942923e-03\n",
    "epoch:  9;\t train:2.680943e-03;0.997842;1.998318e-03;\t test:2.501000e-03;0.997917;1.924351e-03\n",
    "epoch: 10;\t train:2.605840e-03;0.997891;1.972930e-03;\t test:2.449364e-03;0.997935;1.933663e-03\n",
    "epoch: 11;\t train:2.577476e-03;0.997903;1.982632e-03;\t test:2.397660e-03;0.997965;1.926179e-03\n",
    "epoch: 12;\t train:2.541878e-03;0.997927;1.983982e-03;\t test:2.359945e-03;0.997983;1.919877e-03\n",
    "epoch: 13;\t train:2.494848e-03;0.997957;1.971216e-03;\t test:2.312232e-03;0.998019;1.900091e-03\n",
    "epoch: 14;\t train:2.466593e-03;0.997988;1.960540e-03;\t test:2.284799e-03;0.998032;1.899759e-03\n",
    "epoch: 15;\t train:2.457947e-03;0.997982;1.981411e-03;\t test:2.243555e-03;0.998052;1.894299e-03\n",
    "epoch: 16;\t train:2.429429e-03;0.998013;1.970178e-03;\t test:2.250355e-03;0.998027;1.920625e-03\n",
    "epoch: 17;\t train:2.402649e-03;0.998030;1.966258e-03;\t test:2.223356e-03;0.998065;1.908318e-03\n",
    "epoch: 18;\t train:2.390255e-03;0.998038;1.974981e-03;\t test:2.206231e-03;0.998071;1.917248e-03\n",
    "epoch: 19;\t train:2.367898e-03;0.998066;1.960795e-03;\t test:2.170401e-03;0.998084;1.890231e-03\n",
    "epoch: 20;\t train:2.344131e-03;0.998076;1.959478e-03;\t test:2.129293e-03;0.998108;1.868130e-03\n",
    "epoch: 21;\t train:2.338866e-03;0.998077;1.968051e-03;\t test:2.154917e-03;0.998053;1.927810e-03\n",
    "epoch: 22;\t train:2.302718e-03;0.998106;1.942549e-03;\t test:2.101526e-03;0.998115;1.876201e-03\n",
    "epoch: 23;\t train:2.294951e-03;0.998105;1.948545e-03;\t test:2.098920e-03;0.998115;1.896088e-03\n",
    "epoch: 24;\t train:2.276085e-03;0.998120;1.941294e-03;\t test:2.056970e-03;0.998154;1.859453e-03\n",
    "epoch: 25;\t train:2.264403e-03;0.998115;1.941608e-03;\t test:2.052640e-03;0.998124;1.877351e-03\n",
    "epoch: 26;\t train:2.260354e-03;0.998113;1.948789e-03;\t test:2.058990e-03;0.998092;1.875702e-03\n",
    "epoch: 27;\t train:2.236852e-03;0.998134;1.931003e-03;\t test:2.005575e-03;0.998163;1.838868e-03\n",
    "epoch: 28;\t train:2.232741e-03;0.998122;1.941594e-03;\t test:2.030476e-03;0.998078;1.887363e-03\n",
    "epoch: 29;\t train:2.216707e-03;0.998131;1.933649e-03;\t test:2.013064e-03;0.998112;1.881982e-03\n",
    "epoch: 30;\t train:2.222979e-03;0.998120;1.943981e-03;\t test:2.005332e-03;0.998104;1.880990e-03\n",
    "epoch: 31;\t train:2.197646e-03;0.998133;1.928940e-03;\t test:1.989805e-03;0.998133;1.869322e-03\n",
    "epoch: 32;\t train:2.188171e-03;0.998132;1.928132e-03;\t test:1.943455e-03;0.998142;1.831213e-03\n",
    "epoch: 33;\t train:2.172698e-03;0.998137;1.919636e-03;\t test:1.968245e-03;0.998145;1.865805e-03\n",
    "epoch: 34;\t train:2.165373e-03;0.998140;1.917736e-03;\t test:1.944397e-03;0.998130;1.854759e-03\n",
    "epoch: 35;\t train:2.146845e-03;0.998144;1.906808e-03;\t test:1.946058e-03;0.998154;1.856650e-03\n",
    "epoch: 36;\t train:2.142411e-03;0.998138;1.914409e-03;\t test:1.956152e-03;0.998141;1.873982e-03\n",
    "epoch: 37;\t train:2.144842e-03;0.998131;1.919239e-03;\t test:1.905335e-03;0.998136;1.838031e-03\n",
    "epoch: 38;\t train:2.121906e-03;0.998145;1.900020e-03;\t test:1.900747e-03;0.998128;1.840441e-03\n",
    "epoch: 39;\t train:2.126650e-03;0.998135;1.913547e-03;\t test:1.900515e-03;0.998132;1.846817e-03\n",
    "epoch: 40;\t train:2.109421e-03;0.998141;1.900646e-03;\t test:1.867986e-03;0.998141;1.812271e-03\n",
    "epoch: 41;\t train:2.102399e-03;0.998137;1.902353e-03;\t test:1.866618e-03;0.998163;1.820583e-03\n",
    "epoch: 42;\t train:2.090939e-03;0.998140;1.895437e-03;\t test:1.852997e-03;0.998122;1.807541e-03\n",
    "epoch: 43;\t train:2.086240e-03;0.998144;1.892651e-03;\t test:1.874285e-03;0.998136;1.843092e-03\n",
    "epoch: 44;\t train:2.087811e-03;0.998130;1.904639e-03;\t test:1.838054e-03;0.998132;1.813095e-03\n",
    "epoch: 45;\t train:2.066142e-03;0.998143;1.882397e-03;\t test:1.849402e-03;0.998131;1.833414e-03\n",
    "epoch: 46;\t train:2.065486e-03;0.998143;1.888573e-03;\t test:1.823032e-03;0.998143;1.803341e-03\n",
    "epoch: 47;\t train:2.052001e-03;0.998147;1.879360e-03;\t test:1.821962e-03;0.998164;1.818608e-03\n",
    "epoch: 48;\t train:2.068582e-03;0.998125;1.897479e-03;\t test:1.816517e-03;0.998122;1.814412e-03\n",
    "epoch: 49;\t train:2.047156e-03;0.998141;1.883512e-03;\t test:1.798374e-03;0.998159;1.796338e-03\n",
    "epoch: 50;\t train:2.031886e-03;0.998147;1.872911e-03;\t test:1.799203e-03;0.998149;1.805983e-03\n",
    "epoch: 51;\t train:2.035394e-03;0.998140;1.877024e-03;\t test:1.819665e-03;0.998123;1.837259e-03\n",
    "epoch: 52;\t train:2.031265e-03;0.998137;1.875164e-03;\t test:1.790689e-03;0.998180;1.796655e-03\n",
    "epoch: 53;\t train:2.030936e-03;0.998134;1.881265e-03;\t test:1.757891e-03;0.998178;1.768163e-03\n",
    "epoch: 54;\t train:2.011951e-03;0.998141;1.865876e-03;\t test:1.752607e-03;0.998194;1.764886e-03\n",
    "epoch: 55;\t train:2.010856e-03;0.998138;1.870620e-03;\t test:1.758929e-03;0.998166;1.783965e-03\n",
    "epoch: 56;\t train:2.009166e-03;0.998137;1.869881e-03;\t test:1.765247e-03;0.998140;1.791757e-03\n",
    "epoch: 57;\t train:1.999455e-03;0.998141;1.862542e-03;\t test:1.712432e-03;0.998229;1.729272e-03\n",
    "epoch: 58;\t train:1.981395e-03;0.998156;1.846022e-03;\t test:1.753762e-03;0.998143;1.800110e-03\n",
    "epoch: 59;\t train:1.992586e-03;0.998144;1.858229e-03;\t test:1.734627e-03;0.998164;1.771874e-03\n",
    "epoch: 60;\t train:1.983877e-03;0.998148;1.857039e-03;\t test:1.745736e-03;0.998174;1.787201e-03\n",
    "epoch: 61;\t train:1.981486e-03;0.998141;1.857781e-03;\t test:1.715298e-03;0.998182;1.758327e-03\n",
    "epoch: 62;\t train:1.979775e-03;0.998145;1.855493e-03;\t test:1.709974e-03;0.998206;1.751299e-03\n",
    "epoch: 63;\t train:1.960471e-03;0.998153;1.840846e-03;\t test:1.713148e-03;0.998200;1.752935e-03\n",
    "epoch: 64;\t train:1.972453e-03;0.998143;1.851225e-03;\t test:1.706622e-03;0.998167;1.754944e-03\n",
    "epoch: 65;\t train:1.957789e-03;0.998148;1.842534e-03;\t test:1.713661e-03;0.998181;1.761135e-03\n",
    "epoch: 66;\t train:1.962093e-03;0.998143;1.852932e-03;\t test:1.690433e-03;0.998180;1.742558e-03\n",
    "epoch: 67;\t train:1.955345e-03;0.998146;1.840626e-03;\t test:1.719969e-03;0.998179;1.785225e-03\n",
    "epoch: 68;\t train:1.954149e-03;0.998132;1.848344e-03;\t test:1.677744e-03;0.998216;1.724448e-03\n",
    "epoch: 69;\t train:1.950475e-03;0.998137;1.844996e-03;\t test:1.681249e-03;0.998198;1.726423e-03\n",
    "epoch: 70;\t train:1.933044e-03;0.998150;1.830483e-03;\t test:1.677587e-03;0.998204;1.738149e-03\n",
    "epoch: 71;\t train:1.935753e-03;0.998145;1.834977e-03;\t test:1.694410e-03;0.998180;1.755821e-03\n",
    "epoch: 72;\t train:1.934971e-03;0.998151;1.831868e-03;\t test:1.676123e-03;0.998178;1.725187e-03\n",
    "epoch: 73;\t train:1.924191e-03;0.998151;1.825461e-03;\t test:1.686483e-03;0.998144;1.755040e-03\n",
    "epoch: 74;\t train:1.934911e-03;0.998142;1.838315e-03;\t test:1.682897e-03;0.998154;1.761983e-03\n",
    "epoch: 75;\t train:1.909509e-03;0.998160;1.813789e-03;\t test:1.675812e-03;0.998195;1.736362e-03\n",
    "epoch: 76;\t train:1.912688e-03;0.998147;1.820774e-03;\t test:1.693651e-03;0.998190;1.763169e-03\n",
    "epoch: 77;\t train:1.927062e-03;0.998140;1.835051e-03;\t test:1.649372e-03;0.998214;1.703847e-03\n",
    "epoch: 78;\t train:1.915935e-03;0.998141;1.825895e-03;\t test:1.656721e-03;0.998209;1.721991e-03\n",
    "epoch: 79;\t train:1.913782e-03;0.998148;1.824231e-03;\t test:1.660053e-03;0.998217;1.721050e-03\n",
    "epoch: 80;\t train:1.919906e-03;0.998144;1.827577e-03;\t test:1.669771e-03;0.998188;1.743056e-03\n",
    "epoch: 81;\t train:1.903982e-03;0.998152;1.819290e-03;\t test:1.665711e-03;0.998184;1.734419e-03\n",
    "epoch: 82;\t train:1.897988e-03;0.998149;1.813800e-03;\t test:1.648722e-03;0.998202;1.717633e-03\n",
    "epoch: 83;\t train:1.897819e-03;0.998149;1.813106e-03;\t test:1.639902e-03;0.998230;1.708749e-03\n",
    "epoch: 84;\t train:1.896620e-03;0.998151;1.813834e-03;\t test:1.631744e-03;0.998231;1.705451e-03\n",
    "epoch: 85;\t train:1.889391e-03;0.998152;1.807912e-03;\t test:1.627674e-03;0.998226;1.700339e-03\n",
    "epoch: 86;\t train:1.905191e-03;0.998139;1.822928e-03;\t test:1.627593e-03;0.998215;1.694246e-03\n",
    "epoch: 87;\t train:1.887896e-03;0.998149;1.809142e-03;\t test:1.644953e-03;0.998192;1.724741e-03\n",
    "epoch: 88;\t train:1.892425e-03;0.998143;1.812629e-03;\t test:1.639453e-03;0.998188;1.713395e-03\n",
    "epoch: 89;\t train:1.870905e-03;0.998158;1.798784e-03;\t test:1.609467e-03;0.998222;1.687382e-03\n",
    "epoch: 90;\t train:1.886028e-03;0.998142;1.812330e-03;\t test:1.633977e-03;0.998214;1.713824e-03\n",
    "epoch: 91;\t train:1.873257e-03;0.998153;1.800429e-03;\t test:1.615722e-03;0.998201;1.692732e-03\n",
    "epoch: 92;\t train:1.855252e-03;0.998165;1.785483e-03;\t test:1.625933e-03;0.998200;1.718302e-03\n",
    "epoch: 93;\t train:1.873224e-03;0.998147;1.801939e-03;\t test:1.631906e-03;0.998188;1.720618e-03\n",
    "epoch: 94;\t train:1.870745e-03;0.998152;1.799479e-03;\t test:1.610540e-03;0.998178;1.686106e-03\n",
    "epoch: 95;\t train:1.867039e-03;0.998152;1.803204e-03;\t test:1.622419e-03;0.998161;1.703308e-03\n",
    "epoch: 96;\t train:1.862769e-03;0.998153;1.796738e-03;\t test:1.611665e-03;0.998225;1.706182e-03\n",
    "epoch: 97;\t train:1.861185e-03;0.998151;1.793364e-03;\t test:1.600685e-03;0.998217;1.688781e-03\n",
    "epoch: 98;\t train:1.853097e-03;0.998160;1.788689e-03;\t test:1.611765e-03;0.998190;1.705406e-03\n",
    "epoch: 99;\t train:1.866848e-03;0.998145;1.805753e-03;\t test:1.613321e-03;0.998199;1.708685e-03\n",
    "epoch:100;\t train:1.858935e-03;0.998146;1.800397e-03;\t test:1.606181e-03;0.998190;1.700468e-03\n",
    "epoch:101;\t train:1.843513e-03;0.998156;1.782492e-03;\t test:1.556493e-03;0.998254;1.634194e-03\n",
    "epoch:102;\t train:1.833854e-03;0.998169;1.770906e-03;\t test:1.590509e-03;0.998192;1.677711e-03\n",
    "epoch:103;\t train:1.834886e-03;0.998167;1.775626e-03;\t test:1.584757e-03;0.998214;1.680692e-03\n",
    "epoch:104;\t train:1.840464e-03;0.998160;1.780433e-03;\t test:1.554018e-03;0.998235;1.652196e-03\n",
    "epoch:105;\t train:1.838690e-03;0.998159;1.784265e-03;\t test:1.590982e-03;0.998217;1.692341e-03\n",
    "epoch:106;\t train:1.840078e-03;0.998150;1.787428e-03;\t test:1.569602e-03;0.998242;1.661021e-03\n",
    "epoch:107;\t train:1.838843e-03;0.998154;1.783220e-03;\t test:1.579807e-03;0.998209;1.686042e-03\n",
    "epoch:108;\t train:1.823130e-03;0.998165;1.771349e-03;\t test:1.578880e-03;0.998228;1.681079e-03\n",
    "epoch:109;\t train:1.833315e-03;0.998151;1.783809e-03;\t test:1.595508e-03;0.998205;1.686846e-03\n",
    "epoch:110;\t train:1.829910e-03;0.998157;1.777565e-03;\t test:1.542871e-03;0.998250;1.626796e-03\n",
    "epoch:111;\t train:1.829540e-03;0.998152;1.782822e-03;\t test:1.555071e-03;0.998247;1.642241e-03\n",
    "epoch:112;\t train:1.828527e-03;0.998157;1.776615e-03;\t test:1.548235e-03;0.998227;1.643417e-03\n",
    "epoch:113;\t train:1.821225e-03;0.998162;1.771868e-03;\t test:1.545338e-03;0.998247;1.644991e-03\n",
    "epoch:114;\t train:1.827606e-03;0.998159;1.779153e-03;\t test:1.581693e-03;0.998221;1.679929e-03\n",
    "epoch:115;\t train:1.817297e-03;0.998163;1.768557e-03;\t test:1.540013e-03;0.998248;1.637158e-03\n",
    "epoch:116;\t train:1.816239e-03;0.998158;1.770837e-03;\t test:1.561163e-03;0.998234;1.652064e-03\n",
    "epoch:117;\t train:1.815993e-03;0.998163;1.769687e-03;\t test:1.559884e-03;0.998227;1.653681e-03\n",
    "epoch:118;\t train:1.816437e-03;0.998163;1.768844e-03;\t test:1.537855e-03;0.998222;1.642953e-03\n",
    "epoch:119;\t train:1.811125e-03;0.998162;1.769752e-03;\t test:1.552212e-03;0.998191;1.644335e-03\n",
    "epoch:120;\t train:1.814687e-03;0.998157;1.769549e-03;\t test:1.549890e-03;0.998245;1.641505e-03\n",
    "epoch:121;\t train:1.795087e-03;0.998169;1.758831e-03;\t test:1.558060e-03;0.998212;1.656040e-03\n",
    "epoch:122;\t train:1.796156e-03;0.998167;1.757116e-03;\t test:1.558850e-03;0.998208;1.654079e-03\n",
    "epoch:123;\t train:1.806763e-03;0.998164;1.762331e-03;\t test:1.538822e-03;0.998272;1.643013e-03\n",
    "epoch:124;\t train:1.811635e-03;0.998161;1.771061e-03;\t test:1.526807e-03;0.998230;1.628891e-03\n",
    "epoch:125;\t train:1.792232e-03;0.998166;1.755754e-03;\t test:1.517712e-03;0.998257;1.615709e-03\n",
    "epoch:126;\t train:1.783197e-03;0.998179;1.744069e-03;\t test:1.546286e-03;0.998226;1.651016e-03\n",
    "epoch:127;\t train:1.799213e-03;0.998165;1.761646e-03;\t test:1.540074e-03;0.998234;1.638220e-03\n",
    "epoch:128;\t train:1.788565e-03;0.998176;1.753190e-03;\t test:1.540704e-03;0.998248;1.651110e-03\n",
    "epoch:129;\t train:1.791946e-03;0.998173;1.758219e-03;\t test:1.519701e-03;0.998256;1.619973e-03\n",
    "epoch:130;\t train:1.790646e-03;0.998171;1.758240e-03;\t test:1.530527e-03;0.998246;1.632301e-03\n",
    "epoch:131;\t train:1.789778e-03;0.998167;1.754455e-03;\t test:1.514949e-03;0.998238;1.618686e-03\n",
    "epoch:132;\t train:1.782860e-03;0.998174;1.751122e-03;\t test:1.506365e-03;0.998253;1.614137e-03\n",
    "epoch:133;\t train:1.771188e-03;0.998185;1.740943e-03;\t test:1.530092e-03;0.998248;1.641104e-03\n",
    "epoch:134;\t train:1.780641e-03;0.998176;1.748367e-03;\t test:1.521784e-03;0.998261;1.625011e-03\n",
    "epoch:135;\t train:1.786836e-03;0.998167;1.759311e-03;\t test:1.549106e-03;0.998200;1.651723e-03\n",
    "epoch:136;\t train:1.784865e-03;0.998169;1.754299e-03;\t test:1.521030e-03;0.998258;1.628583e-03\n",
    "epoch:137;\t train:1.772981e-03;0.998177;1.745797e-03;\t test:1.503380e-03;0.998263;1.606260e-03\n",
    "epoch:138;\t train:1.769920e-03;0.998178;1.740947e-03;\t test:1.546231e-03;0.998234;1.649825e-03\n",
    "epoch:139;\t train:1.775640e-03;0.998173;1.748346e-03;\t test:1.520206e-03;0.998242;1.628540e-03\n",
    "epoch:140;\t train:1.772643e-03;0.998173;1.744874e-03;\t test:1.529158e-03;0.998217;1.642191e-03\n",
    "epoch:141;\t train:1.769737e-03;0.998170;1.747114e-03;\t test:1.491025e-03;0.998255;1.596497e-03\n",
    "epoch:142;\t train:1.768830e-03;0.998181;1.740348e-03;\t test:1.522195e-03;0.998258;1.621161e-03\n",
    "epoch:143;\t train:1.765201e-03;0.998176;1.745036e-03;\t test:1.498922e-03;0.998274;1.615767e-03\n",
    "epoch:144;\t train:1.778333e-03;0.998168;1.752823e-03;\t test:1.508999e-03;0.998275;1.617835e-03\n",
    "epoch:145;\t train:1.761561e-03;0.998180;1.740740e-03;\t test:1.507031e-03;0.998265;1.618917e-03\n",
    "epoch:146;\t train:1.774187e-03;0.998163;1.754814e-03;\t test:1.517236e-03;0.998247;1.629746e-03\n",
    "epoch:147;\t train:1.757597e-03;0.998182;1.736107e-03;\t test:1.503565e-03;0.998273;1.612169e-03\n",
    "epoch:148;\t train:1.763412e-03;0.998176;1.742283e-03;\t test:1.506706e-03;0.998263;1.616193e-03\n",
    "epoch:149;\t train:1.757785e-03;0.998173;1.737547e-03;\t test:1.480243e-03;0.998275;1.602074e-03\n",
    "epoch:150;\t train:1.762905e-03;0.998174;1.742695e-03;\t test:1.504825e-03;0.998286;1.611754e-03\n",
    "epoch:151;\t train:1.754235e-03;0.998180;1.738769e-03;\t test:1.525399e-03;0.998247;1.630447e-03\n",
    "epoch:152;\t train:1.763337e-03;0.998171;1.742833e-03;\t test:1.483905e-03;0.998279;1.594746e-03\n",
    "epoch:153;\t train:1.755864e-03;0.998180;1.742203e-03;\t test:1.513930e-03;0.998252;1.618112e-03\n",
    "epoch:154;\t train:1.755240e-03;0.998176;1.741225e-03;\t test:1.499906e-03;0.998283;1.610021e-03\n",
    "epoch:155;\t train:1.755923e-03;0.998177;1.741256e-03;\t test:1.502358e-03;0.998259;1.610169e-03\n",
    "epoch:156;\t train:1.754126e-03;0.998180;1.736794e-03;\t test:1.494229e-03;0.998268;1.609049e-03\n",
    "epoch:157;\t train:1.745717e-03;0.998176;1.733727e-03;\t test:1.486005e-03;0.998273;1.593153e-03\n",
    "epoch:158;\t train:1.752799e-03;0.998181;1.736147e-03;\t test:1.494328e-03;0.998252;1.608595e-03\n",
    "epoch:159;\t train:1.739899e-03;0.998184;1.730791e-03;\t test:1.507085e-03;0.998256;1.615232e-03\n",
    "epoch:160;\t train:1.742983e-03;0.998184;1.729794e-03;\t test:1.485578e-03;0.998280;1.590235e-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = test_dataset[0]\n",
    "test_image2, test_label2 = train_transform(test_image, test_label)\n",
    "test_image2 = nd.expand_dims(test_image2,0)\n",
    "print('tensor shape:', test_image2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, cls_preds, box_preds = net(test_image2.as_in_context(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert predictions to real object detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxDetection\n",
    "cls_probs = nd.SoftmaxActivation(nd.transpose(cls_preds, (0, 2, 1)), mode='channel')\n",
    "output = MultiBoxDetection(cls_prob=cls_probs, loc_pred=box_preds, anchor=anchors, force_suppress=True, clip=True, nms_topk=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('cluster')\n",
    "def display(img, out, thresh=0.5):\n",
    "    import random\n",
    "    import matplotlib as mpl\n",
    "    import numpy as np\n",
    "    mpl.rcParams['figure.figsize'] = (10,10)\n",
    "    img = img.asnumpy()\n",
    "    img = np.transpose(img,(2,3,1,0))\n",
    "    img = np.squeeze(img)\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    for det in out:\n",
    "        cid = int(det[0])\n",
    "        if cid == 0:\n",
    "            continue\n",
    "        score = det[1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        scales = [img.shape[1], img.shape[0]] * 2\n",
    "        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].tolist(), scales)]\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                             edgecolor='red', linewidth=3)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = class_names[cid]\n",
    "        plt.gca().text(xmin, ymin-2, '{:s} {:.3f}'.format(text, score),\n",
    "                       bbox=dict(facecolor='red', alpha=0.5),\n",
    "                       fontsize=12, color='white')\n",
    "\n",
    "display(test_image2, output[0].asnumpy(), thresh=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
