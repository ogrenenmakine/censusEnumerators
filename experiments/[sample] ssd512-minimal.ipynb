{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.contrib.ndarray import MultiBoxPrior\n",
    "import matplotlib.pyplot as plt\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict classes\n",
    "- channel `i*(num_class+1)` store the scores for this box contains only background\n",
    "- channel `i*(num_class+1)+1+j` store the scores for this box contains an object from the *j*-th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "def class_predictor(num_anchors, num_classes):\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict anchor boxes\n",
    "- $t_x = (Y_x - b_x) / b_{width}$\n",
    "- $t_y = (Y_y - b_y) / b_{height}$\n",
    "- $t_{width} = (Y_{width} - b_{width}) / b_{width}$\n",
    "- $t_{height} = (Y_{height} - b_{height}) / b_{height}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_predictor(num_anchors):\n",
    "    return nn.Conv2D(num_anchors * 4, 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(num_filters):\n",
    "    out = nn.HybridSequential()\n",
    "    for _ in range(2):\n",
    "        out.add(nn.Conv2D(num_filters, 3, strides=1, padding=1))\n",
    "        out.add(nn.BatchNorm(in_channels=num_filters))\n",
    "        out.add(nn.Activation('relu'))\n",
    "    out.add(nn.MaxPool2D(2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage preditions from multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_prediction(pred):\n",
    "    return nd.flatten(nd.transpose(pred, axes=(0, 2, 3, 1)))\n",
    "\n",
    "def concat_predictions(preds):\n",
    "    return nd.concat(*preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "def body():\n",
    "    out = nn.HybridSequential()\n",
    "    for nfilters in [16, 32, 64]:\n",
    "        out.add(down_sample(nfilters))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a toy SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_ssd_model(num_anchors, num_classes):\n",
    "    downsamples = nn.Sequential()\n",
    "    class_preds = nn.Sequential()\n",
    "    box_preds = nn.Sequential()\n",
    "\n",
    "    downsamples.add(down_sample(128))\n",
    "    downsamples.add(down_sample(128))\n",
    "    downsamples.add(down_sample(128))\n",
    "    \n",
    "    for scale in range(5):\n",
    "        class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "        box_preds.add(box_predictor(num_anchors))\n",
    "    \n",
    "    return body(), downsamples, class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward\n",
    "\n",
    "Given an input and the model, we can run the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_ssd_forward(x, body, downsamples, class_preds, box_preds, sizes, ratios):                    \n",
    "    x = body(x)\n",
    "    default_anchors = []\n",
    "    predicted_boxes = []  \n",
    "    predicted_classes = []\n",
    "                        \n",
    "    for i in range(5):\n",
    "        default_anchors.append(MultiBoxPrior(x, sizes=sizes[i], ratios=ratios[i]))\n",
    "        predicted_boxes.append(flatten_prediction(box_preds[i](x)))\n",
    "        predicted_classes.append(flatten_prediction(class_preds[i](x)))\n",
    "        if i < 3:\n",
    "            x = downsamples[i](x)\n",
    "        elif i == 3:\n",
    "            x = nd.Pooling(x, global_pool=True, pool_type='max', kernel=(4, 4))\n",
    "\n",
    "    return default_anchors, predicted_classes, predicted_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class ToySSD(gluon.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ToySSD, self).__init__(**kwargs)\n",
    "        self.anchor_sizes = [[.2, .272], [.37, .447], [.54, .619], [.71, .79], [.88, .961]]\n",
    "        self.anchor_ratios = [[1, 2, .5]] * 5\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.body, self.downsamples, self.class_preds, self.box_preds = toy_ssd_model(4, num_classes)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        default_anchors, predicted_classes, predicted_boxes = toy_ssd_forward(x, self.body, self.downsamples,\n",
    "            self.class_preds, self.box_preds, self.anchor_sizes, self.anchor_ratios)\n",
    "        anchors = concat_predictions(default_anchors)\n",
    "        box_preds = concat_predictions(predicted_boxes)\n",
    "        class_preds = concat_predictions(predicted_classes)\n",
    "        class_preds = nd.reshape(class_preds, shape=(0, -1, self.num_classes + 1))\n",
    "        \n",
    "        return anchors, class_preds, box_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs of ToySSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ToySSD(2)\n",
    "net.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "#net.load_params(\"process/ssd_49.params\",ctx=ctx)\n",
    "x = nd.zeros((1, 3, 512, 512),ctx=ctx)\n",
    "default_anchors, class_predictions, box_predictions = net(x)\n",
    "print('Outputs:', 'anchors', default_anchors.shape, 'class prediction', class_predictions.shape, 'box prediction', box_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.NACDDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train')])\n",
    "test_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import NACDTransform\n",
    "width, height = 512, 512\n",
    "train_transform = NACDTransform.NACDDefaultTransform(width, height, False)\n",
    "test_transform = NACDTransform.NACDDefaultTransform(width, height, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd\n",
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label = test_dataset[0]\n",
    "bboxes = train_label[:, :4]\n",
    "cids = train_label[:, 4:5]\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2, train_label2 = train_transform(train_image, train_label)\n",
    "print('tensor shape:', train_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset.transform(test_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(test_loader):\n",
    "    if ib > 3:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "train_image2 = (train_image2 * 255).clip(0, 255)\n",
    "ax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxTarget\n",
    "def training_targets(default_anchors, class_predicts, labels):\n",
    "    class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))\n",
    "    z = MultiBoxTarget(anchor=default_anchors.as_in_context(mx.cpu()), label=labels.as_in_context(mx.cpu()), cls_pred=class_predicts.as_in_context(mx.cpu()))\n",
    "    box_target = z[0].as_in_context(ctx)  # box offset target for (x, y, width, height)\n",
    "    box_mask = z[1].as_in_context(ctx)  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples\n",
    "    cls_target = z[2].as_in_context(ctx)  # cls_target is an array of labels for all anchors boxes\n",
    "    return box_target, box_mask, cls_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(gluon.loss.Loss):\n",
    "    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n",
    "        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label):\n",
    "        output = F.softmax(output)\n",
    "        pt = F.pick(output, label, axis=self._axis, keepdims=True)\n",
    "        loss = -self._alpha * ((1 - pt) ** self._gamma) * F.log(pt)\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)\n",
    "\n",
    "# cls_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "cls_loss = FocalLoss()\n",
    "print(cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothL1Loss(gluon.loss.Loss):\n",
    "    def __init__(self, batch_axis=0, **kwargs):\n",
    "        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n",
    "    \n",
    "    def hybrid_forward(self, F, output, label, mask):\n",
    "        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n",
    "        return F.mean(loss, self._batch_axis, exclude=True)\n",
    "\n",
    "box_loss = SmoothL1Loss()\n",
    "print(box_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set context for training\n",
    "ctx = mx.gpu()  # it may takes too long to train using CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mxnet import autograd as ag\n",
    "from gluoncv.loss import SSDMultiBoxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertlbl(y):\n",
    "    mtrx = y[:,:,0:4]\n",
    "    mtrx = mtrx.asnumpy()\n",
    "    mtrx[mtrx == -1] = -width\n",
    "    mtrx = mtrx/512\n",
    "    return mx.nd.concat(nd.expand_dims(y[:,:,4],2),mx.nd.array(mtrx),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop params\n",
    "epochs = 25\n",
    "start_epoch = 1\n",
    "\n",
    "# initialize trainer\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 1e-3, 'wd': 5e-4})\n",
    "\n",
    "# evaluation metrics\n",
    "cls_metric = mx.metric.Accuracy()\n",
    "box_metric = mx.metric.MAE()\n",
    "cls_metric_test = mx.metric.Accuracy()\n",
    "box_metric_test = mx.metric.MAE()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    #train_data.reset()\n",
    "    cls_metric.reset()\n",
    "    box_metric.reset()\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    # iterate through all batch\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            x = batch[0].as_in_context(ctx)\n",
    "            y = batch[1].as_in_context(ctx)\n",
    "            lbl = convertlbl(batch[1])\n",
    "            default_anchors, class_predictions, box_predictions = net(x)\n",
    "            box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "            # losses\n",
    "            loss1 = cls_loss(class_predictions, cls_target)\n",
    "            loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "            # sum all losses\n",
    "            loss = loss1 + loss2\n",
    "            train_loss += nd.sum(loss).asscalar()\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size)\n",
    "        # update metrics\n",
    "        cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "    toc = time.time()\n",
    "    name1_train, val1_train = cls_metric.get()\n",
    "    name2_train, val2_train = box_metric.get()\n",
    "\n",
    "    cls_metric_test.reset()\n",
    "    box_metric_test.reset()\n",
    "    tic = time.time()\n",
    "    test_loss = 0\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        # record gradients\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        y = batch[1].as_in_context(ctx)\n",
    "        lbl = convertlbl(batch[1])\n",
    "        default_anchors, class_predictions, box_predictions = net(x)\n",
    "        box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, lbl)\n",
    "        # losses\n",
    "        loss1 = cls_loss(class_predictions, cls_target)\n",
    "        loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "        # sum all losses\n",
    "        loss = loss1 + loss2\n",
    "        test_loss += nd.sum(loss).asscalar()\n",
    "        # update metrics\n",
    "        cls_metric_test.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric_test.update([box_target], [box_predictions * box_mask])\n",
    "        #if (i + 1) % log_interval == 0:\n",
    "    toc = time.time()\n",
    "    name1_test, val1_test = cls_metric_test.get()\n",
    "    name2_test, val2_test = box_metric_test.get()\n",
    "    print('epoch:%3d;\\t train:%.6e;%f;%.6e;\\t test:%.6e;%f;%.6e'\n",
    "          %(epoch, train_loss/len(train_dataset), val1_train, val2_train, test_loss/len(test_dataset), val1_test, val2_test))\n",
    "\n",
    "    # we can save the trained parameters to disk\n",
    "    net.save_params('process/ssd_%d.params' % epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch:  1;\t train:3.099237e-02;0.955277;1.703118e-02;\t test:1.820281e-02;0.980401;1.465662e-02\n",
    "epoch:  2;\t train:1.770686e-02;0.983614;1.434665e-02;\t test:1.541158e-02;0.983953;1.382904e-02\n",
    "epoch:  3;\t train:1.619971e-02;0.984971;1.382912e-02;\t test:1.388343e-02;0.985066;1.302443e-02\n",
    "epoch:  4;\t train:1.523734e-02;0.985630;1.337600e-02;\t test:1.324065e-02;0.985553;1.270972e-02\n",
    "epoch:  5;\t train:1.458629e-02;0.986040;1.309677e-02;\t test:1.261859e-02;0.986238;1.242178e-02\n",
    "epoch:  6;\t train:1.421841e-02;0.986271;1.295402e-02;\t test:1.251691e-02;0.985778;1.238898e-02\n",
    "epoch:  7;\t train:1.383202e-02;0.986538;1.274954e-02;\t test:1.189846e-02;0.986150;1.202347e-02\n",
    "epoch:  8;\t train:1.365036e-02;0.986621;1.268643e-02;\t test:1.172178e-02;0.986467;1.200340e-02\n",
    "epoch:  9;\t train:1.343251e-02;0.986719;1.261408e-02;\t test:1.170414e-02;0.986607;1.210562e-02\n",
    "epoch: 10;\t train:1.325495e-02;0.986905;1.250753e-02;\t test:1.130400e-02;0.987126;1.183426e-02\n",
    "epoch: 11;\t train:1.302887e-02;0.987068;1.235778e-02;\t test:1.107087e-02;0.987161;1.158755e-02\n",
    "epoch: 12;\t train:1.286008e-02;0.987172;1.229015e-02;\t test:1.110284e-02;0.986883;1.171781e-02\n",
    "epoch: 13;\t train:1.278645e-02;0.987244;1.227626e-02;\t test:1.104754e-02;0.987186;1.181167e-02\n",
    "epoch: 14;\t train:1.267684e-02;0.987323;1.220000e-02;\t test:1.078302e-02;0.987240;1.152418e-02\n",
    "epoch: 15;\t train:1.258322e-02;0.987372;1.217113e-02;\t test:1.072983e-02;0.987295;1.151211e-02\n",
    "epoch: 16;\t train:1.256963e-02;0.987384;1.217628e-02;\t test:1.073542e-02;0.987594;1.160172e-02\n",
    "epoch: 17;\t train:1.241213e-02;0.987482;1.208586e-02;\t test:1.052603e-02;0.987546;1.137898e-02\n",
    "epoch: 18;\t train:1.237113e-02;0.987510;1.208912e-02;\t test:1.041432e-02;0.987545;1.126344e-02\n",
    "epoch: 19;\t train:1.229494e-02;0.987580;1.203294e-02;\t test:1.047146e-02;0.987661;1.146019e-02\n",
    "epoch: 20;\t train:1.229122e-02;0.987541;1.206752e-02;\t test:1.030442e-02;0.987613;1.131399e-02\n",
    "epoch: 21;\t train:1.217564e-02;0.987652;1.198762e-02;\t test:1.034972e-02;0.987758;1.134346e-02\n",
    "epoch: 22;\t train:1.216505e-02;0.987693;1.197095e-02;\t test:1.026508e-02;0.987800;1.130289e-02\n",
    "epoch: 23;\t train:1.208928e-02;0.987698;1.197109e-02;\t test:1.041056e-02;0.987648;1.148678e-02\n",
    "epoch: 24;\t train:1.209269e-02;0.987727;1.194882e-02;\t test:1.007667e-02;0.987920;1.108662e-02\n",
    "epoch: 25;\t train:1.202537e-02;0.987756;1.193400e-02;\t test:1.041837e-02;0.987828;1.150968e-02\n",
    "epoch: 26;\t train:1.198461e-02;0.987774;1.191336e-02;\t test:1.013536e-02;0.987931;1.124197e-02\n",
    "epoch: 27;\t train:1.194248e-02;0.987844;1.186060e-02;\t test:9.963371e-03;0.988257;1.105894e-02\n",
    "epoch: 28;\t train:1.183993e-02;0.987916;1.178838e-02;\t test:1.016723e-02;0.987930;1.127955e-02\n",
    "epoch: 29;\t train:1.192501e-02;0.987810;1.191261e-02;\t test:1.005795e-02;0.988069;1.121526e-02\n",
    "epoch: 30;\t train:1.183942e-02;0.987912;1.181137e-02;\t test:9.872903e-03;0.988330;1.104703e-02\n",
    "epoch: 31;\t train:1.181156e-02;0.987892;1.182759e-02;\t test:9.891690e-03;0.988184;1.099333e-02\n",
    "epoch: 32;\t train:1.176538e-02;0.987942;1.179258e-02;\t test:9.957263e-03;0.988187;1.116358e-02\n",
    "epoch: 33;\t train:1.170621e-02;0.987981;1.176062e-02;\t test:9.926544e-03;0.988186;1.108818e-02\n",
    "epoch: 34;\t train:1.162533e-02;0.988030;1.169738e-02;\t test:1.005381e-02;0.988078;1.131851e-02\n",
    "epoch: 35;\t train:1.161785e-02;0.988058;1.170008e-02;\t test:9.860126e-03;0.988206;1.102731e-02\n",
    "epoch: 36;\t train:1.157414e-02;0.988035;1.168521e-02;\t test:9.785317e-03;0.988373;1.101905e-02\n",
    "epoch: 37;\t train:1.163516e-02;0.987999;1.173739e-02;\t test:9.902835e-03;0.988260;1.119435e-02\n",
    "epoch: 38;\t train:1.157332e-02;0.988054;1.168440e-02;\t test:9.866420e-03;0.988205;1.113309e-02\n",
    "epoch: 39;\t train:1.155411e-02;0.988056;1.169279e-02;\t test:9.674635e-03;0.988428;1.098297e-02\n",
    "epoch: 40;\t train:1.153628e-02;0.988074;1.166415e-02;\t test:9.861207e-03;0.988328;1.112193e-02\n",
    "epoch: 41;\t train:1.145951e-02;0.988133;1.162628e-02;\t test:9.827058e-03;0.988303;1.114280e-02\n",
    "epoch: 42;\t train:1.147701e-02;0.988110;1.164358e-02;\t test:9.652506e-03;0.988389;1.090688e-02\n",
    "epoch: 43;\t train:1.145545e-02;0.988098;1.163966e-02;\t test:9.738765e-03;0.988353;1.103035e-02\n",
    "epoch: 44;\t train:1.137511e-02;0.988161;1.157217e-02;\t test:9.562245e-03;0.988481;1.088333e-02\n",
    "epoch: 45;\t train:1.139021e-02;0.988127;1.162186e-02;\t test:9.842974e-03;0.988288;1.120560e-02\n",
    "epoch: 46;\t train:1.137823e-02;0.988144;1.158603e-02;\t test:9.854199e-03;0.988063;1.119048e-02\n",
    "epoch: 47;\t train:1.138831e-02;0.988122;1.160996e-02;\t test:9.579308e-03;0.988472;1.091858e-02\n",
    "epoch: 48;\t train:1.130679e-02;0.988215;1.151924e-02;\t test:9.561401e-03;0.988537;1.090917e-02\n",
    "epoch: 49;\t train:1.133609e-02;0.988163;1.158947e-02;\t test:9.522632e-03;0.988387;1.085101e-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = test_dataset[0]\n",
    "test_image2, test_label2 = train_transform(test_image, test_label)\n",
    "test_image2 = nd.expand_dims(test_image2,0)\n",
    "print('tensor shape:', test_image2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, cls_preds, box_preds = net(test_image2.as_in_context(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert predictions to real object detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxDetection\n",
    "cls_probs = nd.SoftmaxActivation(nd.transpose(cls_preds, (0, 2, 1)), mode='channel')\n",
    "output = MultiBoxDetection(cls_prob=cls_probs, loc_pred=box_preds, anchor=anchors, force_suppress=True, clip=True, nms_topk=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('cluster')\n",
    "def display(img, out, thresh=0.5):\n",
    "    import random\n",
    "    import matplotlib as mpl\n",
    "    import numpy as np\n",
    "    mpl.rcParams['figure.figsize'] = (10,10)\n",
    "    img = img.asnumpy()\n",
    "    img = np.transpose(img,(2,3,1,0))\n",
    "    img = np.squeeze(img)\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    for det in out:\n",
    "        cid = int(det[0])\n",
    "        if cid == 0:\n",
    "            continue\n",
    "        score = det[1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        scales = [img.shape[1], img.shape[0]] * 2\n",
    "        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].tolist(), scales)]\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                             edgecolor='red', linewidth=3)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = class_names[cid]\n",
    "        plt.gca().text(xmin, ymin-2, '{:s} {:.3f}'.format(text, score),\n",
    "                       bbox=dict(facecolor='red', alpha=0.5),\n",
    "                       fontsize=12, color='white')\n",
    "\n",
    "display(test_image2, output[0].asnumpy(), thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
