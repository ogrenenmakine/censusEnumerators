{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.contrib import nn as nn_contrib\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y, temperature=1.0):\n",
    "    exp = nd.exp(y / temperature)\n",
    "    partition = nd.sum(exp, axis=1).reshape((-1,1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pascal Voc Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from source.NACDVOCDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train'),(2007, 'trainval'), (2012, 'trainval')])\n",
    "val_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test'),(2007, 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 512, 512  # suppose we use 512 as base training size\n",
    "train_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\n",
    "val_transform = presets.ssd.SSDDefaultValTransform(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 24\n",
    "num_workers = 4\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(val_loader):\n",
    "    if ib > 2:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "resnet50 = model_zoo.get_model('resnet50_v2', pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 0.5\n",
    "num_filter = int(32*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_layer(nfilters, stride, expension_constant):\n",
    "    out = nn.HybridSequential()\n",
    "    out.add(nn.Conv2D(nfilters, 3, strides=stride, padding=1, groups=nfilters, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(nfilters*expension_constant, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s16():\n",
    "    out = nn.HybridSequential()\n",
    "    with out.name_scope():\n",
    "        # conv2d\n",
    "        out.add(nn.Conv2D(num_filter, kernel_size=3, strides=2, padding=1, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        \n",
    "        # (3) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter, 1, 1))\n",
    "        #out.add(nn.Conv2D(num_filter, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter, kernel_size=3, strides=1, padding=1, groups=num_filter, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter/2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (4) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter/2, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*3, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu')) # conv2_2_linear_scale\n",
    "        out.add(nn.Conv2D(num_filter*3, kernel_size=3, strides=2, padding=1, groups=num_filter*3, use_bias=False))\n",
    "\n",
    "        out.load_parameters(\"weights/mobilenet_v2_0_5_s16.params\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s32():\n",
    "    out = nn.HybridSequential()\n",
    "    with out.name_scope():\n",
    "        # (4) LinearBottleneck con't\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*3/4, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1)) # conv2_2_linear_scale\n",
    "        \n",
    "        # (5) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*3/4, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*9/2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*9/2, kernel_size=3, strides=1, padding=1, groups=num_filter*9/2, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*6/8, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1)) # conv2_2_linear_scale concatenate\n",
    "\n",
    "        # (6) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*6/8, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*9/2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*9/2, kernel_size=3, strides=2, padding=1, groups=num_filter*9/2, use_bias=False))\n",
    "        \n",
    "        out.load_parameters(\"weights/mobilenet_v2_0_5_s32.params\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc():\n",
    "    out = nn.HybridSequential()\n",
    "    with out.name_scope():\n",
    "        # (6) LinearBottleneck con't\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (7) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*6, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu')) # conv3_2_linear_scale\n",
    "        out.add(nn.Conv2D(num_filter*6, kernel_size=3, strides=1, padding=1, groups=num_filter*6, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (8) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*6, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*6, kernel_size=3, strides=1, padding=1, groups=num_filter*6, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (9) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*6, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu')) # block_4_1\n",
    "        out.add(nn.Conv2D(num_filter*6, kernel_size=3, strides=1,padding=1, groups=num_filter*6, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1)) # block_4_1 concanetate\n",
    "        \n",
    "        # (10) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*2, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*12, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu')) \n",
    "        out.add(nn.Conv2D(num_filter*12, kernel_size=3, strides=1, padding=1, groups=num_filter*12, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (11) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*2, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*12, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*12, kernel_size=3, strides=1, padding=1, groups=num_filter*12, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (12) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*2, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*12, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*12, kernel_size=3, strides=1, padding=1, groups=num_filter*12, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*2, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "\n",
    "        # (13) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*2, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*12, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*12, kernel_size=3, strides=2,padding=1, groups=num_filter*12, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*3, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (14) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*3, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*18, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*18, kernel_size=3, strides=1, padding=1, groups=num_filter*18, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*3, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (15) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*3, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*18, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*18, kernel_size=3, strides=1, padding=1, groups=num_filter*18, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*3, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (16) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*3, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*18, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*18, kernel_size=3, strides=2, padding=1, groups=num_filter*18, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*5, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (17) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*5, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*30, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*30, kernel_size=3, strides=1, padding=1, groups=num_filter*30, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*5, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (18) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*5, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*30, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*30, kernel_size=3, strides=1, padding=1, groups=num_filter*30, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*5, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        # (19) LinearBottleneck\n",
    "        out.add(dp_layer(num_filter*5, 1, 6))\n",
    "        #out.add(nn.Conv2D(num_filter*30, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*30, kernel_size=3, strides=1, padding=1, groups=num_filter*30, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.Conv2D(num_filter*10, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        \n",
    "        out.add(nn.Conv2D(num_filter*80, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "        out.add(nn.Activation('relu'))\n",
    "        out.add(nn.GlobalAvgPool2D())\n",
    "        \n",
    "        out.add(nn.Conv2D(1000, kernel_size=1, strides=1, padding=0, use_bias=False))\n",
    "        out.add(nn.Flatten())\n",
    "        out.load_parameters(\"weights/mobilenet_v2_0_5_fc.params\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mobile(x, s16, s32, fc, temperature):\n",
    "    tic = time.time()\n",
    "    x = s16(x)\n",
    "    \n",
    "    for i in range(16):\n",
    "        x = s32[i](x)\n",
    "        if i == 3:\n",
    "            conv2_2_linear_scale = x\n",
    "        elif i == 11:\n",
    "            x = mx.nd.broadcast_add(conv2_2_linear_scale, x)\n",
    "    print(time.time() - tic)\n",
    "    \n",
    "    for i in range(114):\n",
    "        x = fc[i](x)\n",
    "        if i == 3:\n",
    "            conv3_2_linear_scale = x\n",
    "        elif i == 11:\n",
    "            x = mx.nd.broadcast_add(conv3_2_linear_scale, x)\n",
    "            block_4_1 = x\n",
    "        elif i == 19:\n",
    "            x = mx.nd.broadcast_add(block_4_1, x)\n",
    "        elif i == 27:\n",
    "            conv4_3_linear_scale = x\n",
    "        elif i == 35:\n",
    "            x = mx.nd.broadcast_add(conv4_3_linear_scale, x)\n",
    "            block_4_4 = x\n",
    "        elif i == 43:\n",
    "            x = mx.nd.broadcast_add(block_4_4, x)\n",
    "            block_4_5 = x\n",
    "        elif i == 51:\n",
    "            x = mx.nd.broadcast_add(block_4_5, x)\n",
    "        elif i == 59:\n",
    "            conv4_7_linear_scale = x\n",
    "        elif i == 67:\n",
    "            x = mx.nd.broadcast_add(conv4_7_linear_scale, x)\n",
    "            block_5_1 = x\n",
    "        elif i == 75:\n",
    "            x = mx.nd.broadcast_add(block_5_1, x)\n",
    "        elif i == 83:\n",
    "            conv5_3_linear_scale = x\n",
    "        elif i == 91:\n",
    "            x = mx.nd.broadcast_add(conv5_3_linear_scale, x)\n",
    "            block_6_1 = x\n",
    "        elif i == 99:\n",
    "            x = mx.nd.broadcast_add(block_6_1, x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnet(gluon.Block):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super(mnet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.s16 = s16()\n",
    "            self.s32 = s32()\n",
    "            self.fc = fc()\n",
    "            self.temperature = temperature\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return forward_mobile(x, self.s16, self.s32, self.fc, self.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "epochs = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce = mx.gluon.loss.SoftmaxCrossEntropyLoss(from_logits=True, sparse_label=False)\n",
    "#l2 = mx.gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "temperature = 16\n",
    "from mxnet import autograd as ag\n",
    "net_mobile = mnet(temperature)\n",
    "#net_mobile.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "#net_mobile.load_parameters(\"process/net_mobile_epoch_99.params\")\n",
    "net_mobile.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net_mobile.collect_params(), 'sgd', {'learning_rate': 1e-1, 'wd': 4e-5})\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    tic = time.time()\n",
    "    # iterate through all batch\n",
    "    train_loss = 0\n",
    "    train_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature).detach()\n",
    "        # record gradients\n",
    "        #tic = time.time()\n",
    "        with ag.record():\n",
    "            p = softmax(net_mobile(x),temperature=temperature)\n",
    "            rloss = sce(nd.log(p), slbl)\n",
    "            train_loss += nd.sum(rloss).asscalar()\n",
    "            train_mae.update(preds=p, labels=slbl)\n",
    "            # backpropagate\n",
    "            rloss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size)\n",
    "        #print(time.time() - tic)\n",
    "    btic = time.time()\n",
    "    # iterate through all batch\n",
    "    val_loss = 0\n",
    "    val_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature)\n",
    "        p = softmax(net_mobile(x),temperature=temperature)\n",
    "        rloss = sce(nd.log(p), slbl)\n",
    "        val_loss += nd.sum(rloss).asscalar()\n",
    "        val_mae.update(preds=p, labels=slbl)\n",
    "    print(\"%3d;Loss:%f;Val_loss:%f;Speed:%s;Train_mae:%.6e;Val_mae:%.6e\" % (epoch, train_loss/len(train_dataset), val_loss/len(val_dataset), round(len(train_dataset)/(btic-tic)), train_mae.get()[1], val_mae.get()[1]))\n",
    "    # we can save the trained parameters to disk\n",
    "    net_mobile.save_parameters('process/net_mobile_epoch_%d.params' % (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
