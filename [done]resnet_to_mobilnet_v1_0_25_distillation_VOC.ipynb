{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.contrib import nn as nn_contrib\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y, temperature=1.0):\n",
    "    exp = nd.exp(y / temperature)\n",
    "    partition = nd.sum(exp, axis=1).reshape((-1,1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pascal Voc Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training images:', 27405)\n",
      "('Test images:', 6440)\n"
     ]
    }
   ],
   "source": [
    "from source.NACDVOCDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train'),(2007, 'trainval'), (2012, 'trainval')])\n",
    "val_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test'),(2007, 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 512, 512  # suppose we use 512 as base training size\n",
    "train_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\n",
    "val_transform = presets.ssd.SSDDefaultValTransform(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(val_loader):\n",
    "    if ib > 2:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "resnet50 = model_zoo.get_model('resnet50_v2', pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 0.25\n",
    "num_filters = int(32*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_layer(nfilters, stride, expension_constant):\n",
    "    out = nn.HybridSequential()\n",
    "    out.add(nn.Conv2D(nfilters, 3, strides=stride, padding=1, groups=nfilters, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(nfilters*expension_constant, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "def s16():\n",
    "    out = nn.HybridSequential()\n",
    "    # conv_0 layer\n",
    "    out.add(nn.Conv2D(num_filters, 3, strides=2, padding=1, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_1 layer\n",
    "    out.add(dp_layer(num_filters, 1, 2))\n",
    "    # conv_2 layer\n",
    "    out.add(dp_layer(num_filters*2, 2, 2))\n",
    "    # conv_3 layer\n",
    "    out.add(dp_layer(num_filters*4, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*4, 3, strides=2, padding=1, groups=num_filters*4, use_bias=False))\n",
    "    out.load_parameters(\"weights/mobilenet_0_25_s16_org.params\")\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def s32():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*8, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_4_layer\n",
    "    out.add(dp_layer(num_filters*8, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*8, 3, strides=2, padding=1, groups=num_filters*8, use_bias=False))\n",
    "    out.load_parameters(\"weights/mobilenet_0_25_s32_org.params\")\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def fc():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_5_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_6_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_8_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_9_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_10_layer\n",
    "    out.add(dp_layer(num_filters*16, 2, 2))\n",
    "    # conv_11_layer\n",
    "    out.add(dp_layer(num_filters*32, 1, 1))\n",
    "    out.add(nn.GlobalAvgPool2D())\n",
    "    out.add(nn.Flatten())\n",
    "    out.add(nn.Dense(1000))\n",
    "    out.load_parameters(\"weights/mobilenet_0_25_fc_org.params\")\n",
    "    out.hybridize()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mobile(x, s16, s32, fc, temperature):\n",
    "    x = s16(x)\n",
    "    x = s32(x)\n",
    "    x = fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnet(gluon.Block):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super(mnet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.s16 = s16()\n",
    "            self.s32 = s32()\n",
    "            self.fc = fc()\n",
    "            self.temperature = temperature\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return forward_mobile(x, self.s16, self.s32, self.fc, self.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce = mx.gluon.loss.SoftmaxCrossEntropyLoss(from_logits=True, sparse_label=False)\n",
    "#l2 = mx.gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "temperature = 16\n",
    "from mxnet import autograd as ag\n",
    "net_mobile = mnet(temperature)\n",
    "#net_mobile.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "#net_mobile.load_parameters(\"process/net_mobile_epoch_50.params\")\n",
    "net_mobile.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net_mobile.collect_params(), 'sgd', {'learning_rate': 1e-2, 'wd': 4e-5})\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    tic = time.time()\n",
    "    # iterate through all batch\n",
    "    train_loss = 0\n",
    "    train_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature).detach()\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            p = softmax(net_mobile(x),temperature=temperature)\n",
    "            rloss = sce(nd.log(p), slbl)\n",
    "            train_loss += nd.sum(rloss).asscalar()\n",
    "            train_mae.update(preds=p, labels=slbl)\n",
    "            # backpropagate\n",
    "            rloss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size)\n",
    "    btic = time.time()\n",
    "    # iterate through all batch\n",
    "    val_loss = 0\n",
    "    val_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature)\n",
    "        p = softmax(net_mobile(x),temperature=temperature)\n",
    "        rloss = sce(nd.log(p), slbl)\n",
    "        val_loss += nd.sum(rloss).asscalar()\n",
    "        val_mae.update(preds=p, labels=slbl)\n",
    "    print(\"%3d;Loss:%f;Val_loss:%f;Speed:%s;Train_mae:%.6e;Val_mae:%.6e\" % (epoch, train_loss/len(train_dataset), val_loss/len(val_dataset), round(len(train_dataset)/(btic-tic)), train_mae.get()[1], val_mae.get()[1]))\n",
    "    # we can save the trained parameters to disk\n",
    "    net_mobile.save_parameters('process/net_mobile_epoch_%d.params' % (epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##############  'learning_rate': 1e-1\n",
    " 1;Loss:6.904926;Val_loss:6.907771;Speed:55.0;Train_mae:7.492293e-05;Val_mae:7.189186e-05\n",
    " 2;Loss:6.903616;Val_loss:6.906641;Speed:56.0;Train_mae:6.374476e-05;Val_mae:6.147612e-05\n",
    " 3;Loss:6.911116;Val_loss:6.906082;Speed:56.0;Train_mae:5.789969e-05;Val_mae:5.549044e-05\n",
    " 4;Loss:6.902725;Val_loss:6.905917;Speed:56.0;Train_mae:5.417257e-05;Val_mae:5.357694e-05\n",
    " 5;Loss:6.910549;Val_loss:6.905723;Speed:56.0;Train_mae:5.125361e-05;Val_mae:5.109614e-05\n",
    " 6;Loss:6.902326;Val_loss:6.905578;Speed:56.0;Train_mae:4.909947e-05;Val_mae:4.936126e-05\n",
    " 7;Loss:6.902209;Val_loss:6.905489;Speed:56.0;Train_mae:4.752350e-05;Val_mae:4.819162e-05\n",
    " 8;Loss:6.910174;Val_loss:6.905422;Speed:56.0;Train_mae:4.611367e-05;Val_mae:4.724746e-05\n",
    " 9;Loss:6.902039;Val_loss:6.905362;Speed:56.0;Train_mae:4.502697e-05;Val_mae:4.646171e-05\n",
    "10;Loss:6.910036;Val_loss:6.905305;Speed:56.0;Train_mae:4.420852e-05;Val_mae:4.569984e-05\n",
    "11;Loss:6.901921;Val_loss:6.905246;Speed:56.0;Train_mae:4.349486e-05;Val_mae:4.485687e-05\n",
    "12;Loss:6.901869;Val_loss:6.905232;Speed:56.0;Train_mae:4.263813e-05;Val_mae:4.462457e-05\n",
    "13;Loss:6.909903;Val_loss:6.905232;Speed:56.0;Train_mae:4.227271e-05;Val_mae:4.455207e-05\n",
    "14;Loss:6.901814;Val_loss:6.905162;Speed:56.0;Train_mae:4.165574e-05;Val_mae:4.361183e-05\n",
    "15;Loss:6.909843;Val_loss:6.905152;Speed:56.0;Train_mae:4.140465e-05;Val_mae:4.347671e-05\n",
    "16;Loss:6.901763;Val_loss:6.905131;Speed:56.0;Train_mae:4.107974e-05;Val_mae:4.321318e-05\n",
    "17;Loss:6.901740;Val_loss:6.905113;Speed:56.0;Train_mae:4.056525e-05;Val_mae:4.287421e-05\n",
    "18;Loss:6.909788;Val_loss:6.905104;Speed:56.0;Train_mae:4.035432e-05;Val_mae:4.274275e-05\n",
    "19;Loss:6.901710;Val_loss:6.905087;Speed:55.0;Train_mae:3.999702e-05;Val_mae:4.246529e-05\n",
    "20;Loss:6.909745;Val_loss:6.905073;Speed:56.0;Train_mae:3.980327e-05;Val_mae:4.232444e-05\n",
    "21;Loss:6.901678;Val_loss:6.905077;Speed:56.0;Train_mae:3.966956e-05;Val_mae:4.230528e-05\n",
    "22;Loss:6.901654;Val_loss:6.905055;Speed:56.0;Train_mae:3.952227e-05;Val_mae:4.200033e-05\n",
    "23;Loss:6.909710;Val_loss:6.905040;Speed:55.0;Train_mae:3.935104e-05;Val_mae:4.178987e-05\n",
    "24;Loss:6.901647;Val_loss:6.905039;Speed:55.0;Train_mae:3.905219e-05;Val_mae:4.178026e-05\n",
    "25;Loss:6.909703;Val_loss:6.905025;Speed:55.0;Train_mae:3.874104e-05;Val_mae:4.155917e-05\n",
    "26;Loss:6.901633;Val_loss:6.905028;Speed:55.0;Train_mae:3.865221e-05;Val_mae:4.156273e-05\n",
    "27;Loss:6.901615;Val_loss:6.905018;Speed:56.0;Train_mae:3.855752e-05;Val_mae:4.144277e-05\n",
    "28;Loss:6.909676;Val_loss:6.905002;Speed:56.0;Train_mae:3.836872e-05;Val_mae:4.122274e-05\n",
    "29;Loss:6.901605;Val_loss:6.904998;Speed:56.0;Train_mae:3.828614e-05;Val_mae:4.119516e-05\n",
    "30;Loss:6.909660;Val_loss:6.904982;Speed:56.0;Train_mae:3.821930e-05;Val_mae:4.097338e-05\n",
    "31;Loss:6.901587;Val_loss:6.904979;Speed:56.0;Train_mae:3.809496e-05;Val_mae:4.089809e-05\n",
    "32;Loss:6.901587;Val_loss:6.904974;Speed:56.0;Train_mae:3.801899e-05;Val_mae:4.080441e-05\n",
    "33;Loss:6.909648;Val_loss:6.904964;Speed:56.0;Train_mae:3.771836e-05;Val_mae:4.064448e-05\n",
    "34;Loss:6.901582;Val_loss:6.904964;Speed:56.0;Train_mae:3.762965e-05;Val_mae:4.062633e-05\n",
    "35;Loss:6.909628;Val_loss:6.904957;Speed:56.0;Train_mae:3.765361e-05;Val_mae:4.053973e-05\n",
    "36;Loss:6.901566;Val_loss:6.904955;Speed:56.0;Train_mae:3.757456e-05;Val_mae:4.050836e-05\n",
    "37;Loss:6.901556;Val_loss:6.904945;Speed:56.0;Train_mae:3.753100e-05;Val_mae:4.034292e-05\n",
    "38;Loss:6.909614;Val_loss:6.904939;Speed:56.0;Train_mae:3.741856e-05;Val_mae:4.028512e-05\n",
    "39;Loss:6.901548;Val_loss:6.904936;Speed:55.0;Train_mae:3.731190e-05;Val_mae:4.024998e-05\n",
    "40;Loss:6.909597;Val_loss:6.904928;Speed:56.0;Train_mae:3.742988e-05;Val_mae:4.011404e-05\n",
    "41;Loss:6.901546;Val_loss:6.904922;Speed:56.0;Train_mae:3.720522e-05;Val_mae:4.003679e-05\n",
    "42;Loss:6.901531;Val_loss:6.904924;Speed:56.0;Train_mae:3.720418e-05;Val_mae:4.003845e-05\n",
    "43;Loss:6.909601;Val_loss:6.904913;Speed:56.0;Train_mae:3.715708e-05;Val_mae:3.984978e-05\n",
    "44;Loss:6.901527;Val_loss:6.904914;Speed:56.0;Train_mae:3.709504e-05;Val_mae:3.984798e-05\n",
    "45;Loss:6.909573;Val_loss:6.904913;Speed:56.0;Train_mae:3.688719e-05;Val_mae:3.985613e-05\n",
    "46;Loss:6.901524;Val_loss:6.904900;Speed:56.0;Train_mae:3.689608e-05;Val_mae:3.968269e-05\n",
    "47;Loss:6.901522;Val_loss:6.904901;Speed:56.0;Train_mae:3.687919e-05;Val_mae:3.969465e-05\n",
    "48;Loss:6.909578;Val_loss:6.904900;Speed:56.0;Train_mae:3.681258e-05;Val_mae:3.964842e-05\n",
    "49;Loss:6.901506;Val_loss:6.904896;Speed:56.0;Train_mae:3.671760e-05;Val_mae:3.962815e-05\n",
    "50;Loss:6.909557;Val_loss:6.904888;Speed:56.0;Train_mae:3.669046e-05;Val_mae:3.946084e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
