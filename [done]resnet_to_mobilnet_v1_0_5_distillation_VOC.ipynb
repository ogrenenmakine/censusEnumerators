{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.contrib import nn as nn_contrib\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y, temperature=1.0):\n",
    "    exp = nd.exp(y / temperature)\n",
    "    partition = nd.sum(exp, axis=1).reshape((-1,1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pascal Voc Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from source.NACDVOCDetection import NACDDetection\n",
    "\n",
    "train_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'train'),(2007, 'trainval'), (2012, 'trainval')])\n",
    "val_dataset = NACDDetection(splits=[('NACDwNegswAugCropped', 'test'),(2007, 'test')])\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Test images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 512, 512  # suppose we use 512 as base training size\n",
    "train_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\n",
    "val_transform = presets.ssd.SSDDefaultValTransform(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(val_loader):\n",
    "    if ib > 2:\n",
    "        break\n",
    "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label = val_dataset[0]\n",
    "train_image2, train_label2 = train_transform(train_image, train_label)\n",
    "print('tensor shape:', train_image2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "resnet50 = model_zoo.get_model('resnet50_v2', pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global alpha\n",
    "alpha = 0.5\n",
    "num_filters = int(32*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_layer(nfilters, stride, expension_constant):\n",
    "    out = nn.HybridSequential()\n",
    "    out.add(nn.Conv2D(nfilters, 3, strides=stride, padding=1, groups=nfilters, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(nfilters*expension_constant, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "def s16():\n",
    "    out = nn.HybridSequential()\n",
    "    # conv_0 layer\n",
    "    out.add(nn.Conv2D(num_filters, 3, strides=2, padding=1, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_1 layer\n",
    "    out.add(dp_layer(num_filters, 1, 2))\n",
    "    # conv_2 layer\n",
    "    out.add(dp_layer(num_filters*2, 2, 2))\n",
    "    # conv_3 layer\n",
    "    out.add(dp_layer(num_filters*4, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*4, 3, strides=2, padding=1, groups=num_filters*4, use_bias=False))\n",
    "    out.load_parameters(\"weights/mobilenet_0_5_s16_org.params\")\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def s32():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*8, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_4_layer\n",
    "    out.add(dp_layer(num_filters*8, 1, 1))\n",
    "    out.add(nn.Conv2D(num_filters*8, 3, strides=2, padding=1, groups=num_filters*8, use_bias=False))\n",
    "    out.load_parameters(\"weights/mobilenet_0_5_s32_org.params\")\n",
    "    out.hybridize()\n",
    "    return out\n",
    "\n",
    "def fc():\n",
    "    out = nn.HybridSequential()\n",
    "    # from last layer\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    out.add(nn.Conv2D(num_filters*16, 1, strides=1, padding=0, use_bias=False))\n",
    "    out.add(nn.BatchNorm(use_global_stats=False, epsilon=1e-05, momentum=0.9, axis=1))\n",
    "    out.add(nn.Activation('relu'))\n",
    "    # conv_5_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_6_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_7_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_8_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_9_layer\n",
    "    out.add(dp_layer(num_filters*16, 1, 1))\n",
    "    # conv_10_layer\n",
    "    out.add(dp_layer(num_filters*16, 2, 2))\n",
    "    # conv_11_layer\n",
    "    out.add(dp_layer(num_filters*32, 1, 1))\n",
    "    out.add(nn.GlobalAvgPool2D())\n",
    "    out.add(nn.Flatten())\n",
    "    out.add(nn.Dense(1000))\n",
    "    out.load_parameters(\"weights/mobilenet_0_5_fc_org.params\")\n",
    "    out.hybridize()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mobile(x, s16, s32, fc, temperature):\n",
    "    x = s16(x)\n",
    "    x = s32(x)\n",
    "    x = fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnet(gluon.Block):\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super(mnet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.s16 = s16()\n",
    "            self.s32 = s32()\n",
    "            self.fc = fc()\n",
    "            self.temperature = temperature\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return forward_mobile(x, self.s16, self.s32, self.fc, self.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce = mx.gluon.loss.SoftmaxCrossEntropyLoss(from_logits=True, sparse_label=False)\n",
    "#l2 = mx.gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "temperature = 16\n",
    "from mxnet import autograd as ag\n",
    "net_mobile = mnet(temperature)\n",
    "#net_mobile.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "#net_mobile.load_parameters(\"process/net_mobile_epoch_1.params\")\n",
    "net_mobile.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net_mobile.collect_params(), 'sgd', {'learning_rate': 1e-1, 'wd': 4e-5})\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    tic = time.time()\n",
    "    # iterate through all batch\n",
    "    train_loss = 0\n",
    "    train_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature).detach()\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            p = softmax(net_mobile(x),temperature=temperature)\n",
    "            rloss = sce(nd.log(p), slbl)\n",
    "            train_loss += nd.sum(rloss).asscalar()\n",
    "            train_mae.update(preds=p, labels=slbl)\n",
    "            # backpropagate\n",
    "            rloss.backward()\n",
    "        # apply \n",
    "        trainer.step(batch_size)\n",
    "    btic = time.time()\n",
    "    # iterate through all batch\n",
    "    val_loss = 0\n",
    "    val_mae = mx.metric.MAE()\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        x = batch[0].as_in_context(ctx)\n",
    "        slbl = softmax(resnet50(x),temperature=temperature)\n",
    "        p = softmax(net_mobile(x),temperature=temperature)\n",
    "        rloss = sce(nd.log(p), slbl)\n",
    "        val_loss += nd.sum(rloss).asscalar()\n",
    "        val_mae.update(preds=p, labels=slbl)\n",
    "    print(\"%3d;Loss:%f;Val_loss:%f;Speed:%s;Train_mae:%.6e;Val_mae:%.6e\" % (epoch, train_loss/len(train_dataset), val_loss/len(val_dataset), round(len(train_dataset)/(btic-tic)), train_mae.get()[1], val_mae.get()[1]))\n",
    "    # we can save the trained parameters to disk\n",
    "    net_mobile.save_parameters('process/net_mobile_epoch_%d.params' % (epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  0;Loss:6.904240;Val_loss:6.906884;Speed:47.0;Train_mae:7.079974e-05;Val_mae:6.354899e-05\n",
    "  1;Loss:6.902989;Val_loss:6.906124;Speed:48.0;Train_mae:5.969190e-05;Val_mae:5.552766e-05\n",
    "  2;Loss:6.909564;Val_loss:6.905640;Speed:48.0;Train_mae:5.381133e-05;Val_mae:4.973278e-05\n",
    "  3;Loss:6.902110;Val_loss:6.905376;Speed:48.0;Train_mae:4.982678e-05;Val_mae:4.626692e-05\n",
    "  4;Loss:6.909005;Val_loss:6.905254;Speed:48.0;Train_mae:4.683271e-05;Val_mae:4.453505e-05\n",
    "  5;Loss:6.901728;Val_loss:6.905136;Speed:48.0;Train_mae:4.462652e-05;Val_mae:4.280291e-05\n",
    "  6;Loss:6.908730;Val_loss:6.905114;Speed:48.0;Train_mae:4.310484e-05;Val_mae:4.240621e-05\n",
    "  7;Loss:6.901530;Val_loss:6.905007;Speed:48.0;Train_mae:4.175246e-05;Val_mae:4.084543e-05\n",
    "  8;Loss:6.908596;Val_loss:6.904974;Speed:48.0;Train_mae:4.072561e-05;Val_mae:4.028735e-05\n",
    "  9;Loss:6.901417;Val_loss:6.904907;Speed:48.0;Train_mae:3.986960e-05;Val_mae:3.933584e-05\n",
    " 10;Loss:6.908491;Val_loss:6.904892;Speed:48.0;Train_mae:3.931140e-05;Val_mae:3.910514e-05\n",
    " 11;Loss:6.901339;Val_loss:6.904868;Speed:48.0;Train_mae:3.857061e-05;Val_mae:3.864297e-05\n",
    " 12;Loss:6.908426;Val_loss:6.904866;Speed:48.0;Train_mae:3.813591e-05;Val_mae:3.860163e-05\n",
    " 13;Loss:6.901287;Val_loss:6.904854;Speed:48.0;Train_mae:3.770027e-05;Val_mae:3.840031e-05\n",
    " 14;Loss:6.908392;Val_loss:6.904821;Speed:48.0;Train_mae:3.732847e-05;Val_mae:3.795348e-05\n",
    " 15;Loss:6.901245;Val_loss:6.904820;Speed:48.0;Train_mae:3.702265e-05;Val_mae:3.789632e-05\n",
    " 16;Loss:6.901220;Val_loss:6.904804;Speed:48.0;Train_mae:3.682143e-05;Val_mae:3.757940e-05\n",
    " 17;Loss:6.908323;Val_loss:6.904803;Speed:48.0;Train_mae:3.655828e-05;Val_mae:3.760759e-05\n",
    " 18;Loss:6.901192;Val_loss:6.904781;Speed:48.0;Train_mae:3.624989e-05;Val_mae:3.719322e-05\n",
    " 19;Loss:6.908309;Val_loss:6.904793;Speed:48.0;Train_mae:3.604292e-05;Val_mae:3.741711e-05\n",
    " 20;Loss:6.901162;Val_loss:6.904760;Speed:48.0;Train_mae:3.585284e-05;Val_mae:3.693699e-05\n",
    " 21;Loss:6.908277;Val_loss:6.904757;Speed:48.0;Train_mae:3.554944e-05;Val_mae:3.686299e-05\n",
    " 22;Loss:6.901155;Val_loss:6.904763;Speed:48.0;Train_mae:3.556326e-05;Val_mae:3.687511e-05\n",
    " 23;Loss:6.908271;Val_loss:6.904741;Speed:48.0;Train_mae:3.540130e-05;Val_mae:3.659185e-05\n",
    " 24;Loss:6.901134;Val_loss:6.904754;Speed:48.0;Train_mae:3.529844e-05;Val_mae:3.674750e-05\n",
    " 25;Loss:6.908238;Val_loss:6.904740;Speed:48.0;Train_mae:3.506762e-05;Val_mae:3.652708e-05\n",
    " 26;Loss:6.901125;Val_loss:6.904728;Speed:48.0;Train_mae:3.494630e-05;Val_mae:3.633420e-05\n",
    " 27;Loss:6.908213;Val_loss:6.904735;Speed:48.0;Train_mae:3.483306e-05;Val_mae:3.647254e-05\n",
    " 28;Loss:6.901108;Val_loss:6.904718;Speed:48.0;Train_mae:3.469240e-05;Val_mae:3.612576e-05\n",
    " 29;Loss:6.908223;Val_loss:6.904718;Speed:48.0;Train_mae:3.463602e-05;Val_mae:3.612357e-05\n",
    " 30;Loss:6.901081;Val_loss:6.904719;Speed:48.0;Train_mae:3.451687e-05;Val_mae:3.617138e-05\n",
    " 31;Loss:6.908210;Val_loss:6.904704;Speed:48.0;Train_mae:3.444007e-05;Val_mae:3.593375e-05\n",
    " 32;Loss:6.901092;Val_loss:6.904699;Speed:48.0;Train_mae:3.428306e-05;Val_mae:3.587183e-05\n",
    " 33;Loss:6.901073;Val_loss:6.904699;Speed:48.0;Train_mae:3.417722e-05;Val_mae:3.583622e-05\n",
    " 34;Loss:6.908188;Val_loss:6.904698;Speed:48.0;Train_mae:3.415482e-05;Val_mae:3.584063e-05\n",
    " 35;Loss:6.901060;Val_loss:6.904695;Speed:48.0;Train_mae:3.410037e-05;Val_mae:3.571723e-05\n",
    " 36;Loss:6.908188;Val_loss:6.904683;Speed:48.0;Train_mae:3.396973e-05;Val_mae:3.554584e-05\n",
    " 37;Loss:6.901055;Val_loss:6.904672;Speed:48.0;Train_mae:3.398767e-05;Val_mae:3.541086e-05\n",
    " 38;Loss:6.908164;Val_loss:6.904674;Speed:48.0;Train_mae:3.391902e-05;Val_mae:3.541117e-05\n",
    " 39;Loss:6.901051;Val_loss:6.904675;Speed:48.0;Train_mae:3.379073e-05;Val_mae:3.543958e-05\n",
    " 40;Loss:6.908175;Val_loss:6.904672;Speed:48.0;Train_mae:3.364647e-05;Val_mae:3.538999e-05\n",
    " 41;Loss:6.901036;Val_loss:6.904666;Speed:48.0;Train_mae:3.364971e-05;Val_mae:3.526629e-05\n",
    " 42;Loss:6.908151;Val_loss:6.904685;Speed:48.0;Train_mae:3.350811e-05;Val_mae:3.551891e-05\n",
    " 43;Loss:6.901033;Val_loss:6.904669;Speed:48.0;Train_mae:3.359205e-05;Val_mae:3.530997e-05\n",
    " 44;Loss:6.908140;Val_loss:6.904667;Speed:48.0;Train_mae:3.345529e-05;Val_mae:3.525057e-05\n",
    " 45;Loss:6.901022;Val_loss:6.904661;Speed:48.0;Train_mae:3.337829e-05;Val_mae:3.515627e-05\n",
    " 46;Loss:6.908132;Val_loss:6.904651;Speed:48.0;Train_mae:3.330911e-05;Val_mae:3.499967e-05\n",
    " 47;Loss:6.901005;Val_loss:6.904662;Speed:48.0;Train_mae:3.334039e-05;Val_mae:3.520929e-05\n",
    " 48;Loss:6.901019;Val_loss:6.904652;Speed:48.0;Train_mae:3.328398e-05;Val_mae:3.498480e-05\n",
    " 49;Loss:6.908135;Val_loss:6.904650;Speed:48.0;Train_mae:3.325702e-05;Val_mae:3.493797e-05\n",
    " 50;Loss:6.901010;Val_loss:6.904653;Speed:48.0;Train_mae:3.314515e-05;Val_mae:3.498431e-05\n",
    " 51;Loss:6.908136;Val_loss:6.904646;Speed:48.0;Train_mae:3.310137e-05;Val_mae:3.486346e-05\n",
    " 52;Loss:6.901006;Val_loss:6.904639;Speed:48.0;Train_mae:3.306405e-05;Val_mae:3.476386e-05\n",
    " 53;Loss:6.908114;Val_loss:6.904633;Speed:48.0;Train_mae:3.313640e-05;Val_mae:3.467131e-05\n",
    " 54;Loss:6.900990;Val_loss:6.904638;Speed:48.0;Train_mae:3.296712e-05;Val_mae:3.474897e-05\n",
    " 55;Loss:6.908114;Val_loss:6.904633;Speed:48.0;Train_mae:3.286732e-05;Val_mae:3.465421e-05\n",
    " 56;Loss:6.900995;Val_loss:6.904627;Speed:48.0;Train_mae:3.287519e-05;Val_mae:3.458051e-05\n",
    " 57;Loss:6.908114;Val_loss:6.904629;Speed:48.0;Train_mae:3.287956e-05;Val_mae:3.457810e-05\n",
    " 58;Loss:6.900998;Val_loss:6.904631;Speed:48.0;Train_mae:3.285024e-05;Val_mae:3.460438e-05\n",
    " 59;Loss:6.908098;Val_loss:6.904631;Speed:48.0;Train_mae:3.275327e-05;Val_mae:3.460064e-05\n",
    " 60;Loss:6.900977;Val_loss:6.904628;Speed:48.0;Train_mae:3.283842e-05;Val_mae:3.457175e-05\n",
    " 61;Loss:6.908100;Val_loss:6.904629;Speed:48.0;Train_mae:3.276604e-05;Val_mae:3.456603e-05\n",
    " 62;Loss:6.900982;Val_loss:6.904622;Speed:48.0;Train_mae:3.274445e-05;Val_mae:3.443623e-05\n",
    " 63;Loss:6.908089;Val_loss:6.904626;Speed:48.0;Train_mae:3.242210e-05;Val_mae:3.451604e-05\n",
    " 64;Loss:6.900964;Val_loss:6.904632;Speed:48.0;Train_mae:3.263676e-05;Val_mae:3.459472e-05\n",
    " 65;Loss:6.900981;Val_loss:6.904618;Speed:48.0;Train_mae:3.253002e-05;Val_mae:3.434519e-05\n",
    " 66;Loss:6.908090;Val_loss:6.904619;Speed:48.0;Train_mae:3.248416e-05;Val_mae:3.437523e-05\n",
    " 67;Loss:6.900964;Val_loss:6.904612;Speed:48.0;Train_mae:3.242853e-05;Val_mae:3.426145e-05\n",
    " 68;Loss:6.908094;Val_loss:6.904623;Speed:48.0;Train_mae:3.244616e-05;Val_mae:3.444973e-05\n",
    " 69;Loss:6.900963;Val_loss:6.904619;Speed:48.0;Train_mae:3.246110e-05;Val_mae:3.438489e-05\n",
    " 70;Loss:6.908085;Val_loss:6.904618;Speed:48.0;Train_mae:3.238834e-05;Val_mae:3.437629e-05\n",
    " 71;Loss:6.900957;Val_loss:6.904609;Speed:48.0;Train_mae:3.239000e-05;Val_mae:3.415849e-05\n",
    " 72;Loss:6.908087;Val_loss:6.904610;Speed:48.0;Train_mae:3.237125e-05;Val_mae:3.418137e-05\n",
    " 73;Loss:6.900944;Val_loss:6.904608;Speed:48.0;Train_mae:3.239892e-05;Val_mae:3.414508e-05\n",
    " 74;Loss:6.908083;Val_loss:6.904603;Speed:48.0;Train_mae:3.232733e-05;Val_mae:3.408639e-05\n",
    " 75;Loss:6.900949;Val_loss:6.904614;Speed:48.0;Train_mae:3.227601e-05;Val_mae:3.427939e-05\n",
    " 76;Loss:6.908077;Val_loss:6.904603;Speed:48.0;Train_mae:3.226380e-05;Val_mae:3.407014e-05\n",
    " 77;Loss:6.900952;Val_loss:6.904606;Speed:48.0;Train_mae:3.217453e-05;Val_mae:3.408095e-05\n",
    " 78;Loss:6.908078;Val_loss:6.904604;Speed:48.0;Train_mae:3.217028e-05;Val_mae:3.408007e-05\n",
    " 79;Loss:6.900967;Val_loss:6.904601;Speed:48.0;Train_mae:3.209249e-05;Val_mae:3.401344e-05\n",
    " 80;Loss:6.900951;Val_loss:6.904605;Speed:48.0;Train_mae:3.214120e-05;Val_mae:3.410888e-05\n",
    " 81;Loss:6.908063;Val_loss:6.904600;Speed:48.0;Train_mae:3.206401e-05;Val_mae:3.398571e-05\n",
    " 82;Loss:6.900950;Val_loss:6.904605;Speed:48.0;Train_mae:3.211095e-05;Val_mae:3.407192e-05\n",
    " 83;Loss:6.908065;Val_loss:6.904597;Speed:48.0;Train_mae:3.219555e-05;Val_mae:3.393694e-05\n",
    " 84;Loss:6.900937;Val_loss:6.904605;Speed:48.0;Train_mae:3.202504e-05;Val_mae:3.408068e-05\n",
    " 85;Loss:6.908068;Val_loss:6.904598;Speed:48.0;Train_mae:3.200236e-05;Val_mae:3.392110e-05\n",
    " 86;Loss:6.900950;Val_loss:6.904599;Speed:48.0;Train_mae:3.195943e-05;Val_mae:3.394464e-05\n",
    " 87;Loss:6.908065;Val_loss:6.904597;Speed:48.0;Train_mae:3.197899e-05;Val_mae:3.392539e-05\n",
    " 88;Loss:6.900946;Val_loss:6.904600;Speed:48.0;Train_mae:3.194786e-05;Val_mae:3.395784e-05\n",
    " 89;Loss:6.908067;Val_loss:6.904599;Speed:48.0;Train_mae:3.189460e-05;Val_mae:3.392363e-05\n",
    " 90;Loss:6.900942;Val_loss:6.904600;Speed:48.0;Train_mae:3.193731e-05;Val_mae:3.393523e-05\n",
    " 91;Loss:6.908059;Val_loss:6.904597;Speed:48.0;Train_mae:3.198148e-05;Val_mae:3.390501e-05\n",
    " 92;Loss:6.900948;Val_loss:6.904596;Speed:48.0;Train_mae:3.197668e-05;Val_mae:3.385050e-05\n",
    " 93;Loss:6.908062;Val_loss:6.904599;Speed:48.0;Train_mae:3.193221e-05;Val_mae:3.392164e-05\n",
    " 94;Loss:6.900940;Val_loss:6.904610;Speed:48.0;Train_mae:3.184789e-05;Val_mae:3.412827e-05\n",
    " 95;Loss:6.908047;Val_loss:6.904593;Speed:48.0;Train_mae:3.190338e-05;Val_mae:3.382388e-05\n",
    " 96;Loss:6.900938;Val_loss:6.904591;Speed:48.0;Train_mae:3.204195e-05;Val_mae:3.378215e-05\n",
    " 97;Loss:6.900942;Val_loss:6.904599;Speed:48.0;Train_mae:3.191340e-05;Val_mae:3.393102e-05\n",
    " 98;Loss:6.908049;Val_loss:6.904604;Speed:48.0;Train_mae:3.192530e-05;Val_mae:3.399019e-05\n",
    " 99;Loss:6.900924;Val_loss:6.904596;Speed:48.0;Train_mae:3.187986e-05;Val_mae:3.385225e-05\n",
    "100;Loss:6.908051;Val_loss:6.904599;Speed:48.0;Train_mae:3.172575e-05;Val_mae:3.386128e-05\n",
    "101;Loss:6.900947;Val_loss:6.904594;Speed:48.0;Train_mae:3.193044e-05;Val_mae:3.377240e-05\n",
    "102;Loss:6.908042;Val_loss:6.904594;Speed:48.0;Train_mae:3.187911e-05;Val_mae:3.376674e-05\n",
    "103;Loss:6.900932;Val_loss:6.904598;Speed:48.0;Train_mae:3.183196e-05;Val_mae:3.385574e-05\n",
    "104;Loss:6.908068;Val_loss:6.904594;Speed:48.0;Train_mae:3.186543e-05;Val_mae:3.375788e-05\n",
    "105;Loss:6.900923;Val_loss:6.904592;Speed:48.0;Train_mae:3.187782e-05;Val_mae:3.372650e-05\n",
    "106;Loss:6.908049;Val_loss:6.904594;Speed:48.0;Train_mae:3.177769e-05;Val_mae:3.375614e-05\n",
    "107;Loss:6.900935;Val_loss:6.904602;Speed:48.0;Train_mae:3.180658e-05;Val_mae:3.385022e-05\n",
    "108;Loss:6.908053;Val_loss:6.904594;Speed:48.0;Train_mae:3.187276e-05;Val_mae:3.378462e-05\n",
    "109;Loss:6.900936;Val_loss:6.904601;Speed:48.0;Train_mae:3.182704e-05;Val_mae:3.382929e-05\n",
    "110;Loss:6.908049;Val_loss:6.904606;Speed:48.0;Train_mae:3.184610e-05;Val_mae:3.392537e-05\n",
    "111;Loss:6.900932;Val_loss:6.904596;Speed:48.0;Train_mae:3.172553e-05;Val_mae:3.372235e-05\n",
    "112;Loss:6.900935;Val_loss:6.904601;Speed:48.0;Train_mae:3.174652e-05;Val_mae:3.381278e-05\n",
    "113;Loss:6.908071;Val_loss:6.904599;Speed:48.0;Train_mae:3.180540e-05;Val_mae:3.379265e-05\n",
    "114;Loss:6.900936;Val_loss:6.904594;Speed:48.0;Train_mae:3.175276e-05;Val_mae:3.368971e-05\n",
    "115;Loss:6.908056;Val_loss:6.904605;Speed:48.0;Train_mae:3.178321e-05;Val_mae:3.386864e-05\n",
    "116;Loss:6.900927;Val_loss:6.904600;Speed:48.0;Train_mae:3.192776e-05;Val_mae:3.375892e-05\n",
    "117;Loss:6.908063;Val_loss:6.904607;Speed:48.0;Train_mae:3.190525e-05;Val_mae:3.393727e-05\n",
    "118;Loss:6.900932;Val_loss:6.904603;Speed:48.0;Train_mae:3.181744e-05;Val_mae:3.380709e-05\n",
    "119;Loss:6.908056;Val_loss:6.904607;Speed:48.0;Train_mae:3.191373e-05;Val_mae:3.388518e-05\n",
    "120;Loss:6.900933;Val_loss:6.904605;Speed:48.0;Train_mae:3.174938e-05;Val_mae:3.383555e-05\n",
    "121;Loss:6.908050;Val_loss:6.904603;Speed:48.0;Train_mae:3.181881e-05;Val_mae:3.380556e-05\n",
    "122;Loss:6.900937;Val_loss:6.904607;Speed:48.0;Train_mae:3.179906e-05;Val_mae:3.384426e-05\n",
    "123;Loss:6.908059;Val_loss:6.904606;Speed:48.0;Train_mae:3.182392e-05;Val_mae:3.382412e-05\n",
    "124;Loss:6.900934;Val_loss:6.904605;Speed:48.0;Train_mae:3.174678e-05;Val_mae:3.382851e-05\n",
    "125;Loss:6.908056;Val_loss:6.904607;Speed:48.0;Train_mae:3.190320e-05;Val_mae:3.385139e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
